{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Apsvt5Ouip3"
      },
      "source": [
        "# Workshop: Introduction to Machine Learning for Qualitative Research\n",
        "\n",
        "Thanks for checking out this interactive python notebook! It runs through google colab to allow including bit of software. The notebook walks you through the deep-learning-powered workflow we developed to help analyze large volumes of ethnographic data.\n",
        "\n",
        "You can read about our team [here] and access our code repo [here]. Some  more resources for  integrating qualitative research and computation are available [here](https://cmabramson.com/resources). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNSVZsvcvfM4"
      },
      "source": [
        "## Introduction to Python in Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0YVTZQ1vh5R"
      },
      "source": [
        "You are in google colaboratory (or 'colab'). Colab is free for noncomercial use. Colab allows you to write and execute Python code in your web browser without having to set up a programming environment on your computer. Colab also has tools for annotation, so we set it up like an interactive wiki.\n",
        "\n",
        "You can **click the sidebar button** on the left to show or hide the _table of Contents_. Clicking \"**cell(s) hidden**\" will reveal more. You can also expand sections by clicking the small arrows to the left of headers. Clicking the arrow again will hide the next cell.\n",
        "\n",
        " Try this now with the header \"practice running code.\" \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYsnXiLT0a6J"
      },
      "source": [
        "### Practice Running Code \n",
        "\n",
        "You can execute embedded code by clicking on the arrow to the left of the cell. This is how we run programs or use functions. Try this below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5Q8nKXX0fmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab40a4d-51a6-477c-bb99-57efa9cba421"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world, I am here to code your qualitative data more efficiently!\n"
          ]
        }
      ],
      "source": [
        "print (\"Hello world, I am here to code your qualitative data more efficiently!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqB3IAx0wk3"
      },
      "source": [
        "Now run the simple program below. It will ask for your name, and say if it likes it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE6dQzIp0xGa",
        "outputId": "3a23dbab-ff3f-4b84-9761-77e589349b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is your name? Corey\n",
            "Meh!\n"
          ]
        }
      ],
      "source": [
        "name = input('What is your name? ')\n",
        "if name == 'Avery':\n",
        "  print('Awesome name!', name, 'is pretty cool.')\n",
        "elif name == \"Zhuofan\":\n",
        "  print('Good name!', name, 'is pretty cool.')\n",
        "elif name == \"Dan\":\n",
        "  print('Good name!', name, 'is pretty cool.')\n",
        "elif name == \"Corey\":\n",
        "  print('Meh!')\n",
        "else:\n",
        "  print(' Well', name, ', your name is good I guess.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8wYITdy5ARU"
      },
      "source": [
        "Now that you understand the basics of this interface, the rest of this notebook will walk you through our deep-learning-powered workflow [new blog link]. You can expand the background section below to read more background if you like!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rlIpTDK30Gc"
      },
      "source": [
        "## Background: Coding Qualitative Interviews and Fieldnotes with HHMLA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TGQyVPV3M7z"
      },
      "source": [
        "### What is Coding?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HpqDU_C3NMK"
      },
      "source": [
        "Coding is like adding hashtags (#'s) to the text in your qualitative data. In qualitative research, this usually involves a researcher saying this paragraph of fieldnotes, interview response, or document is an example of *something*. Like [#talk_of_morality](https://link.springer.com/article/10.1007/s11133-010-9175-8). Coding allows us to see themes and patterns in a study. It also helps retrieve key text when writing, allows more complex analyses or comparisons, and can help produce interesting visualizations.  You can read about what coding is and is not [here](https://cmabramson.com/resources/f/qualitative-coding-simplified). \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV5qorcr3NWM"
      },
      "source": [
        "### Why Machine Learning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkZsGennvAcy"
      },
      "source": [
        "One of the problems with coding data is that it takes a long time, but  still requires flexibility to identify new patterns in data. Contemporary natural language processing (NLP) techniques use machine learning to  speed up the process. The basic idea is to get a computer to help accurately classify paragraphs of text by [learning from human coders](https://cmabramson.com/resources/f/using-machine-learning-with-ethnographic-interviews) familiar with the data. You can read about technical details [here](https://osf.io/preprints/socarxiv/gpr4n/).\n",
        "\n",
        "Over the course of our work with the [Medical Cultures Lab ](https://www.cultureofmedicine.org/research/metholdology)at UCSF, we developed an approach  called HHMLA (short for: Hybrid Human-Machine Learning Approach) that uses a combination of traditional human coding and NLP to efficiently index a lot of qualitative data with high accuracy. It also identifies patterns human coders miss. Importantly, HHMLA maintains the flexibility and iteration that lead us to use qualitive research in the first place.   As a bonus, it does not require a huge volume of data anymore thanks to advances in AI. You can read more about it [here](https://cmabramson.com/resources/f/using-machine-learning-with-ethnographic-interviews).\n",
        "\n",
        "*NOTE: Sometimes machine learning has been done as a way to bypass an interpretive human reading. Our goal here is to show how the process of human coding can be extended efficiently, not replaced. This reflects our epistemic comitments, but may work well for other approaches too.*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How is this Different From Using a Dictionary Based Approach to Text Analysis?"
      ],
      "metadata": {
        "id": "-x_5ehPGeSik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previous approaches to automating qualitative coding rely heavily on prespecified rules, statistical assumptions, or dictionaries of keywords, often at the price of interpretative adaptability. \n",
        "\n",
        "Recent developments in deep learning models of natural languages provide a promising opportunity for qualitative researchers to scale their coding without compromising adaptability. Instead of following prespecified rules, deep learning algorithms are designed to mimic human behavior using human-generated examples. \n",
        "\n",
        "For instance... a [dictionary based approach may miss 'kick the bucket'] when looking for talk of death. An approach using machine learning would learn this idiom from human coding.\n",
        "\n",
        "After iteratively establishing a codebook and some learning examples by hand-coding a sample of qualitative data, deep learning can help researchers quickly scale their initial codings on the remaining data and save up time and energy for thinking deeply about the data and the code. \n"
      ],
      "metadata": {
        "id": "JzGAZqmFPenz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Machine Learning Glossary "
      ],
      "metadata": {
        "id": "yDtfKZu8YGj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Machine learning: the ability of an computer algorithm to build models based on sample data and make predictions and decisions on unseen data without being explicitly programmed to do so. An example is Google Search's autocomplete: When you type something in the search bar, it will predict the next word you are going to type and make suggestions. \n",
        "\n",
        "- Training data: a dataset of examples used by machine learning algorithms to learn patterns and build predictive models. \n",
        "\n",
        "- Test data: a dataset of examples used to provide an unbiased evaluation of how well trained models can make predictions. \n",
        "\n",
        "- Classification tasks: the task of assigning a class labels to input examples. An example is spam detection: many email services will classify incoming emails into spams and non-spams based on the content of the email. \n",
        "\n",
        "- Recall: measures how many percentage of all relevant cases a model picks up in a classification task. Suppose you are in a restaurant, a waiter misses three out of four items you ordered has a recall of 0.25, and of course you want a waiter with higher recall! \n",
        "\n",
        "- Precision: measures how many percentage of cases a model picks up are actually relevant in a classification task. Suppose you are in a restaurant, your waiter brings to you four items, but three out of the four items are items that you didn't order. This waiter has a precision of 25%, and of course you want a waiter with higher precision! \n",
        "\n",
        "- F-1: measures the overall performance of a machine learning model in classification tasks. "
      ],
      "metadata": {
        "id": "lYuX9XXYYL8J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Zo_i6v0zAN"
      },
      "source": [
        "## Overview of  Workflow\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*NOTES*\n",
        "\n",
        "*   *This notebook will walk through a  workflow for using machine learning to code in-depth interview data.*\n",
        "*  *In our real world application, we used qualitative data and codings from the Patient Deliberation Study described [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4730903/).* \n",
        "\n",
        "*   *For the demo, we only use publically available information from the oral history archive [here](https://ethw.org/Oral-History:List_of_all_Oral_Histories).* \n",
        "*   *Uploading confidential human subjects data to google colab may create ethical and/or institutional issues, so we are not recomending its use in this capacity.Python can be configured to run in secure data enviornments.*  \n",
        "*   *The appendix at the end of the  notebook has code that illustrates how we scrapped the webpage.*\n",
        "\n"
      ],
      "metadata": {
        "id": "dok_Qd8GchG7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xeprVM24-8R"
      },
      "source": [
        "Our workflow here presupposes that you have some qualitative data and that is coded in a consistant way. Although a simplified explanation of coding is provided [here](https://cmabramson.com/resources/f/qualitative-coding-simplified), collecting data, developing a codebook, and applying codes consistently to that data is a task beyond the scope of this tutorial. So we start at the point in a project where:\n",
        "1. We have some relatively stable codes.\n",
        "2. Have applied those codes to qualitative data (e.g. quotes from interviews).\n",
        "3. But still have a bunch of text--maybe a few dozen (or hundred) interviews, or a years worth of field notes-- that need to get coded...\n",
        "\n",
        "At this point we need to do the following:\n",
        "1. Export the coded data in a table. \n",
        "2. Import the coded data into python\n",
        "3. Train the AI to scale the codes to the remaining data\n",
        "4. Evaluate, tune, and possibly recode for better accuracy\n",
        "5. Export the data.\n",
        "6. (Optionally) Import [link] the data into a QDA program like ATLAS.ti, for more analytical options.\n",
        "7. Make sense of the data and write up our findings.\n",
        "\n",
        "We will cover steps 2-5.\n",
        "\n",
        "Figure 1 provides a visualization. Yes, it is an attempt at a vaporwave aesthetic.\n",
        "[link]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl-C_rm26mzU"
      },
      "source": [
        "## Part I: Preparing Data \n",
        "Data from in-depth interviews should be formatted as follows:\n",
        "1. Each row should be a unit of text (usually a paragraph or question response)\n",
        "2. That text should be included in a column labeled 'quotation content'.\n",
        "3. Another column should be labeled 'Codes,' and have codes listed in []\n",
        "4. Additional columns can be used to identify which interview the text is part of, and where in the interview it occurs. This allows reconstruction in other software.  \n",
        "\n",
        "This will look something like this:\n",
        "[link]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exporting Data from ATLAS.ti\n",
        "We have a tutorial on how to do this using ATLAS.ti, the QDA software our team uses [here](https://cmabramson.com/resources/f/sub-setting-qualitative-data-for-machine-learning), but you can export a similar table using other programs or compile text using python. "
      ],
      "metadata": {
        "id": "RcWrgsUYkL-R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeNxG3c28g6a"
      },
      "source": [
        "### Importing Data into Python\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGs8qVHwAsJ_"
      },
      "source": [
        "After we export the interview data to an Excel file, we then tell the program where to find it. \n",
        "\n",
        "We can also specify the minimum length of each paragraph (in character), meaning any paragraph shorter than this minimum will be ignored. We set the number to be 50 characters, so that filler paragraphs such as \"Yep\", \"Okay\" and \"I see\" will not be used as training data. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"https://github.com/lizhuofan95/ASA2022_Workshop/blob/main/data/oralhistory_coded_short.xlsx?raw=true\"\n",
        "\n",
        "min_length = 50"
      ],
      "metadata": {
        "id": "qXJao9XVkV4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell will load the actual Excel file based on the oral history project data hosted on our GitHub repository. It imports the formated data into Python. "
      ],
      "metadata": {
        "id": "ddcWxsJxyT7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*NOTE: The dash symbols inside code cells denote comments that will not run when you run the whole cell.* \n",
        "\n",
        "*Sometimes we use dash symbols to \"comment out\" code that we don't need for the time being but can be later \"uncommented\" and run in other circumstances.* \n",
        "\n",
        "*Lines enclosed by triple quotation marks are docstrings that many developers use to describe in detail what the function does. These also will not run when you run the cell.*"
      ],
      "metadata": {
        "id": "SxEZcqb7XkF5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDQY5Zqi79XO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # The most commonly used library for data wrangling in Python\n",
        "\n",
        "def read_ATLAS(path, min_length = -1):\n",
        "    \"\"\"\n",
        "      Loads data ATLAS.ti-generated export files in .xls/.xlsx format, creates a copy that includes only participants' \n",
        "      speeches over a certain length for machine learning, and transforms the \"Codes\" column to one-hot encoding. \n",
        "\n",
        "      Args:\n",
        "          path: file path to an ATLAS export file. It must have one paragraph per row and for each paragraph \n",
        "                include the following columns:\n",
        "\n",
        "                    - Document: unique interview id\n",
        "                    - Reference: unique pragraph id\n",
        "                    - Quotation Content: paragraph content\n",
        "                    - Codes: a list of codes that have been manually assigned to the paragraph\n",
        "\n",
        "          min_length = the minimum number of characters that a paragraph must include to be included as valid data. This is to \n",
        "                       exclude filler sentences such as \"yeah\", \"no\", \"I know\" etc. Only comes into effect if you specify a \n",
        "                       value that is greater or equal to 1. \n",
        "      Returns: \n",
        "          original: the original, abbreviated version of the data, which we will use for reimporting machine-generated codings back into ATLAS.ti.\n",
        "          training: the abbrevaited version of the data, which we will use for machine learning. \n",
        "    \"\"\"\n",
        "    \n",
        "    data = pd.read_excel(path, engine='openpyxl', dtype = str)[['Document', 'Reference', 'Quotation Content', 'Codes']]\n",
        "    \n",
        "    data['Codes'] = data['Codes'].apply(lambda x: str(x).split(\"\\n\"))\n",
        "    data['Quote'] = data['Quotation Content']\n",
        "\n",
        "    data['Codes_Frozen'] = data['Codes'].apply(frozenset).to_frame(name='Codes_Frozen')\n",
        "    for code in frozenset.union(*data.Codes_Frozen):\n",
        "        data[code] = data.apply(lambda _: int(code in _.Codes_Frozen), axis=1)\n",
        "    \n",
        "    original = data\n",
        "\n",
        "    # data['Quotation Content'] = data['Quotation Content'].apply(lambda x: str(x).split(\"\\t\"))\n",
        "    # N = len(data)\n",
        "    # data['Spk'] = \"\"\n",
        "    # data['Quote'] = \"\"\n",
        "    # for i in range(N):\n",
        "    #     line = data['Quotation Content'][i]\n",
        "    #     if len(line) >= 2:\n",
        "    #         data['Spk'][i] = line[0].strip(\":\\s\")\n",
        "    #         data['Quote'][i] = line[1].strip('\\u202c')\n",
        "    #     elif len(line) == 1:\n",
        "    #         data['Spk'][i] = \"\"\n",
        "    #         data['Quote'][i] = line[0].strip()\n",
        "    #     else:\n",
        "    #         data['Spk'][i] = data['Quote'] = \"\"\n",
        "    #     data['Codes'][i] = [data['Codes'][i][j].strip(\"#\") for j in range(len(data['Codes'][i]))]\n",
        "    # data = data[data[\"Spk\"].isin([\"MSPKR\",\"FSPKR\"])].reset_index(drop = True)\n",
        "    # data = data[(data[\"Spk\"] != \"\") & (data[\"INT_NEW\"] != 1)].reset_index(drop = True)\n",
        "    \n",
        "    if min_length >= 0: \n",
        "        data = data[data['Quote'].map(len) >= min_length].reset_index(drop = True)  # Filter out paragraphs below the minimum length\n",
        "        \n",
        "    training = data[[col for col in data.columns if col not in ['Quotation Content', 'Codes', 'Spk', 'Codes_Frozen', 'nan']]]\n",
        "    \n",
        "    return original, training\n",
        "\n",
        "original, training = read_ATLAS(path = path, min_length = min_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h-M0YxNB4Va"
      },
      "source": [
        "This is how our data should look after import, one unit of analysis of text per row with identifiers and metadata. A wide range of computational tools will  become available once you transform any text data into this format.\n",
        "\n",
        "**p.s. Don't worry, you can transform it back later.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "R59itba5B754",
        "outputId": "4662f38d-80ec-4cdb-eae2-a67a2a090e17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Document Reference  \\\n",
              "0        Henry_B._Abajian         0   \n",
              "1        Henry_B._Abajian         1   \n",
              "2        Henry_B._Abajian         2   \n",
              "3        Henry_B._Abajian         3   \n",
              "4        Henry_B._Abajian         5   \n",
              "...                   ...       ...   \n",
              "19976  Anthony_Zimbalatti    177036   \n",
              "19977  Anthony_Zimbalatti    177038   \n",
              "19978  Anthony_Zimbalatti    177039   \n",
              "19979  Anthony_Zimbalatti    177041   \n",
              "19980  Anthony_Zimbalatti    177042   \n",
              "\n",
              "                                                   Quote  Background  \n",
              "0      This is an interview with Henry Abajian on the...           1  \n",
              "1      In 1938 I graduated with an electrical enginee...           1  \n",
              "2      What were you particularly interested in at th...           1  \n",
              "3      It was all power engineering, and the electron...           0  \n",
              "4      Yes. How I got there was interesting. The head...           0  \n",
              "...                                                  ...         ...  \n",
              "19976  Before we talk about your Grumman experiences ...           0  \n",
              "19977  What at the time caused you and your colleague...           0  \n",
              "19978  I don't know. We always had these bull session...           0  \n",
              "19979  Both of us worked for Milt. I think he had an ...           0  \n",
              "19980  That was the problem. There was a need felt fo...           0  \n",
              "\n",
              "[19981 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee9b4ed8-0a4d-4549-9ce7-4e1e58c811eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Quote</th>\n",
              "      <th>Background</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>0</td>\n",
              "      <td>This is an interview with Henry Abajian on the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>1</td>\n",
              "      <td>In 1938 I graduated with an electrical enginee...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>2</td>\n",
              "      <td>What were you particularly interested in at th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>3</td>\n",
              "      <td>It was all power engineering, and the electron...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes. How I got there was interesting. The head...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19976</th>\n",
              "      <td>Anthony_Zimbalatti</td>\n",
              "      <td>177036</td>\n",
              "      <td>Before we talk about your Grumman experiences ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19977</th>\n",
              "      <td>Anthony_Zimbalatti</td>\n",
              "      <td>177038</td>\n",
              "      <td>What at the time caused you and your colleague...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19978</th>\n",
              "      <td>Anthony_Zimbalatti</td>\n",
              "      <td>177039</td>\n",
              "      <td>I don't know. We always had these bull session...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19979</th>\n",
              "      <td>Anthony_Zimbalatti</td>\n",
              "      <td>177041</td>\n",
              "      <td>Both of us worked for Milt. I think he had an ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19980</th>\n",
              "      <td>Anthony_Zimbalatti</td>\n",
              "      <td>177042</td>\n",
              "      <td>That was the problem. There was a need felt fo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19981 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee9b4ed8-0a4d-4549-9ce7-4e1e58c811eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee9b4ed8-0a4d-4549-9ce7-4e1e58c811eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee9b4ed8-0a4d-4549-9ce7-4e1e58c811eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkV4vMDpCKi6"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b92lKgGYCTF5"
      },
      "source": [
        "For machine learning models to learn how humans code qualitative data, we also need to transform any raw text to something that computer can understand: numbers. \n",
        "\n",
        "People have come up with many ways of using numbers to represent text, but most of those systems are static and purely representational (e.g. Morse code), not for understanding the semantics and mimicing the human usage of human languages. \n",
        "\n",
        "Recent developments in natural language processing have nonetheless made many breakthroughs towards this direction, by using deep learning models trained on enourmous volumes of text data to generate high-dimensional vectors representing raw text such that the resulting representations can be used to learn and mimic how language is used. \n",
        "\n",
        "And our goal is precisely to mimic how human researchers code interviews. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "_We use BERT, or Bidirectional Encoder Representation from Transformers, a family of deep learning language models trained on thousands of millions English words from sources like Google Books and Wikipedia to generate fine-grained and context-specific representations of language._"
      ],
      "metadata": {
        "id": "SBz_3aBwB6Is"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II: Train the AI"
      ],
      "metadata": {
        "id": "6nyypyzgI8LT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up a Deep Learning Environment\n",
        "\n",
        "This cell sets up the computational environment in Google Colab. This will allow us to use machine learning.\n",
        "\n",
        "Before you run the cell below, go to \"Runtime - Change Runtime Type - Hardware Accelerator\" and select \"GPU\". This will speed up our model. "
      ],
      "metadata": {
        "id": "fOlKR8MAuxE0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cpFbVN-CCxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab81e7d-577e-4b1a-97e3-88d3160e74b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 34.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 73.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" # or \"cpu\"\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "\n",
        "def text2feature(text, MAX_LENGTH = 512, BATCH_SIZE = 16, device = device):\n",
        "    \"\"\"\n",
        "    Use pretrained BERT model to vectorize raw text. \n",
        "    \n",
        "    Args:\n",
        "        text: the text of interest, stored in the \"Quote\" column of our DataFrame \"data_ML\". \n",
        "        \n",
        "        MAX_LENGTH: the maximum number of \"wordpieces\" (usually words but not always) in each paragraph to be used \n",
        "                    for representing the paragraph, capped at 512. \n",
        "        \n",
        "        BATCH_SIZE: the maximum number of samples to be used in a single neural network iteration. It is recommended\n",
        "                    to use a batch size of 32 or 64. We used 16 due to the limitation of our GPU memory. \n",
        "        \n",
        "        device: \"CPU\" or \"cuda\". \"cuda\" is the architecture of the NVIDIA graphics processing unit (GPU) which is\n",
        "                used to accelerate machine learning. Only use if you either (1) have a NVIDIA GPU and have installed \n",
        "                the CUDA development tools following the instruction or (2) use cloud computing (e.g. Google Colab). \n",
        "        \n",
        "    Returns: \n",
        "        feature: an N_row by 768 array of vectors that represent each paragraph using a vector of 768.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    \n",
        "    encodings = list(map(lambda t: tokenizer.encode(t, padding=True, truncation=True, max_length = MAX_LENGTH, add_special_tokens=True), text))\n",
        "    \n",
        "    max_len = 0\n",
        "    for i in encodings:\n",
        "        if len(i) > max_len:\n",
        "            max_len = len(i)\n",
        "\n",
        "    encodings_padded = np.array([i + [0]*(max_len-len(i)) for i in encodings])\n",
        "    attention_mask = [[float(i > 0) for i in ii] for ii in encodings_padded]\n",
        "    \n",
        "    dataset = TensorDataset(torch.tensor(encodings_padded, dtype = torch.int), torch.tensor(attention_mask))\n",
        "    \n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
        "    \n",
        "    model = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)\n",
        "    \n",
        "    features = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for step_num, batch_data in enumerate(dataloader):\n",
        "            token_ids, masks = tuple(t.to(device) for t in batch_data)\n",
        "            last_hidden_states = model(token_ids, masks)\n",
        "            features.append(last_hidden_states[0][:,0,:].cpu().detach().numpy())\n",
        "            \"\"\"\n",
        "            The model actually produces a vector of 768 for each of the 512 \"wordpiece\" in every sequence, but the \n",
        "            vector of every sequence, denoted by [CLS], is always a special classification token that can be used as\n",
        "            the aggregate sequence representation for classification tasks. An alterantive is to represent the sequence\n",
        "            by averaging all 512 vectors, which tends to produce similar results.           \n",
        "            \"\"\"\n",
        "    features = np.vstack(features)\n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsGy7FbbDEFX"
      },
      "source": [
        "### From Text to Vectors Using Deep Learning\n",
        "\n",
        "On average this will take about 5-7 minutes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcyBCSceCC55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238,
          "referenced_widgets": [
            "8c4a90edb9d5438aa9e9387e4d704091",
            "5003410dd60d43faa2dee15328d4f54f",
            "84d6305d0f2a46dba9d9d6fb84d6f70f",
            "bed4c4d6cc92449cb795297e0fb94149",
            "74a791de36644b85bee19cc36caa5805",
            "f21cccf4480e43d0b30c1a6dda736fb0",
            "417336142a6f434093cbdd6fcee7c747",
            "d23f637143b54292b683709efd550b70",
            "7c854e1f291640c3b2422d8e83ede99b",
            "a2301cc6bbad4d58b901983bf93c7d83",
            "1fd2568180504acba9519205e50ddca7",
            "3909dc2e5dba4424a805b575259b335a",
            "10f1916f08164f74a57eabbbee3ad294",
            "964d0c8ca73a40dda54a6f3d1a93eff1",
            "148a5bd765134a5da72cda1fd04669a2",
            "3edccff71d6e4da79d391e2a534e3522",
            "0779ef32f0d74fb08cf23b647b5b6045",
            "b2bcf7bfc9804a8bbe46a73d5e8c6952",
            "844c1c0227664906be286e1bb147ad82",
            "1b05f772268a4018933ddf6fa65f919c",
            "94278ea9681f43bbae1f4b309c0a59ff",
            "92c1ad0638ed499f8995b03e30580c77",
            "03b79b1ca5034b6cbc3eea6d9b577956",
            "92d92426dd1b4c28b5e691812c79292e",
            "b7e5ae1286da4a3f92cca75adb89934d",
            "b60a171b67fa4d13a2cac39eeca7958b",
            "55f86f21b200411b97d6c6c769677222",
            "4e1293a89f604c9192c4dcddf799455b",
            "a985a5bcf5924357a9cd54d2f436985a",
            "8f923ae8c7704c5d80de08020efbb2a3",
            "d97b41387de649ba82175311307f3977",
            "08328134a8ae4b6fa405cccaeb5e7e87",
            "aed4a7824bde404fb85b5fd9dcf704c6",
            "a746becb328c4fa78160a0903440800a",
            "e7cbfe96bf114b4d8057e3ce2920b510",
            "2c3989f20e1149939aa23d5f505c56b5",
            "99b82a33592247009d0f5201ba246310",
            "9f6dfcd2d6c14667bfabf802efcebedd",
            "b854b213bbdf4ef798ffb24a36576892",
            "2f0ec48f2b204bbbbdda579352691f98",
            "ffea5c307fa3459aa603e743a4553d83",
            "400bdce66bcb4beb945950ce0603a606",
            "baa6c1673a674eaba2f915fdc4547b11",
            "ed5e737d76c842298fca71f69271ec12"
          ]
        },
        "outputId": "f7e15208-e404-41f3-ce20-63a0053b250d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c4a90edb9d5438aa9e9387e4d704091",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3909dc2e5dba4424a805b575259b335a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03b79b1ca5034b6cbc3eea6d9b577956",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a746becb328c4fa78160a0903440800a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19981, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "text = training['Quote'].values.tolist()   # Extract text from the DataFrame\n",
        "features = text2feature(text)              # This function transforms text data into vectors. \n",
        "features.shape                             # We should obtain a N × 768 matrix that represents each row using a 768-dimensional vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uzUb9zrDKAi"
      },
      "source": [
        "Our data look like this in vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwqJz37LCC8X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325788cc-9b20-4fe7-fd9f-4b7456a85473"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-8.04037899e-02, -1.23658910e-01, -3.61755282e-01, ...,\n",
              "        -4.42422088e-03,  5.73920608e-01,  4.51830387e-01],\n",
              "       [ 1.52352005e-02,  7.93554708e-02, -3.65893543e-01, ...,\n",
              "         2.96420068e-01,  3.53529871e-01,  6.38014317e-01],\n",
              "       [ 1.67413235e-01, -4.30313461e-02, -2.37162262e-01, ...,\n",
              "        -1.04779854e-01,  2.66423166e-01,  2.84095228e-01],\n",
              "       ...,\n",
              "       [-8.22876766e-02,  5.59788980e-02, -4.67753440e-01, ...,\n",
              "         1.56504020e-01,  7.09437609e-01,  3.97252321e-01],\n",
              "       [ 1.43082321e-01, -1.50504559e-01, -4.59693998e-01, ...,\n",
              "        -5.96625090e-04,  4.93743062e-01,  5.25567591e-01],\n",
              "       [-6.87612742e-02,  3.02690975e-02, -1.31134659e-01, ...,\n",
              "        -1.04792535e-01,  1.61510170e-01,  2.77071506e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Those numbers are not just any arbitrary numbers! They provide relational representations, as well as we can get in computers, of the linguistic and semantic features of each paragraph as it is composed and used in the context. These representations will help the algorithm find the paragraphs that are relevant to our coding. "
      ],
      "metadata": {
        "id": "v1D8pY7mwHC_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpCR8nBmEpqC"
      },
      "source": [
        "### Generate Testing Samples for Evaluation\n",
        "\n",
        "But before we use these vectors to extend our initial codings to all the remaining data, we want to have an sense of how reliable it would be. We do so by setting aside a small sample of coded data and compare machine-generated codings against our own codings on this already coded sample. And we want to do this multiple times to weed out the effect of outlier cases. \n",
        "\n",
        "We tell the algorithm how many times we want to test what percentage of the data we want to use for testing. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 20       # how many randomly reshuffled splits to generate.\n",
        "test_size = 0.75    # how many cases to use as test data. "
      ],
      "metadata": {
        "id": "Q7H6hxNg6YZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GIKgORtElY3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "def split(all_cases, n_splits = 10, test_size = 0.25):\n",
        "    \"\"\"\n",
        "    Split any coded data into training and test sets. \n",
        "    \n",
        "    Args:\n",
        "        n_splits: how many randomly reshuffled splits to generate. The default is 10. \n",
        "        \n",
        "        test_size: how many cases to use as test data. \n",
        "                   - If between 0 and 1, represents the proportion of the dataset to include;\n",
        "                   - If integer greater than 1, represents the the absolute number of test samples.\n",
        "                   - The default is 25%. \n",
        "    Returns:\n",
        "        train_set, test_set\n",
        "    \n",
        "    \"\"\"\n",
        "    train_test_split = ShuffleSplit(n_splits = n_splits, test_size = test_size)\n",
        "    train_set = []\n",
        "    test_set = []\n",
        "    for train_index, test_index in train_test_split.split(all_cases):\n",
        "        train_set.append(train_index.tolist())\n",
        "        test_set.append(test_index.tolist())\n",
        "    \n",
        "    return train_set, test_set\n",
        "\n",
        "all_cases = training['Document'].unique().tolist()\n",
        "\n",
        "train_set, test_set = split(all_cases, n_splits, test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_The more data we use for testing, the less data we have left for training._\n",
        "\n",
        "_Here we are testing on all the remaining data because all the paragraphs are \"coded\" already in our \"toy dataset\". In actual research, we would code 25% of all data, use 15-20% to train the model, and 5%-10% to evaluate its performance, and then scale the codings to the remaining 75%._"
      ],
      "metadata": {
        "id": "vkEdDSSs2Coz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW5wKZ_oGrPS"
      },
      "source": [
        "## Part III: Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzD16qYKG0Zq"
      },
      "source": [
        "Now we train a classifier algorithm to predict our own codings using the vector representations and training examples we just obtained. \n",
        "\n",
        "First, we tell the algorithm which code we have already established on the training data and want to scale to the remaining data. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_codes = ['Background']"
      ],
      "metadata": {
        "id": "02zm52RikAnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAY_6iiiGxD4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "4d0ea1ad-0ec9-4feb-ebae-e6229b1980a3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-419db3f7bc32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_codes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'N'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_codes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kappa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-419db3f7bc32>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(classifier, data, eval_codes, train_set, test_set, method)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
          ]
        }
      ],
      "source": [
        "# since BERT is typically deployed with data that are much bigger and deep \n",
        "# learning models much more sophisticated than required by our tasks, here \n",
        "# we simplify it by combining BERT vectors with a regularized logistic \n",
        "# regression, which we found to be highly effective for smaller scale data. \n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, cohen_kappa_score\n",
        "\n",
        "from typing import Union\n",
        "from scipy.sparse import spmatrix\n",
        "\n",
        "NDArray = Union[np.ndarray, spmatrix]\n",
        "\n",
        "class Classifier:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initalizes a logistic regression classifier.\n",
        "        \"\"\"\n",
        "        self.clf = LogisticRegression(penalty = 'l2', solver = 'liblinear', C = 1, class_weight= 'balanced')\n",
        "        \n",
        "    def train(self, features: NDArray, labels: NDArray):\n",
        "        \"\"\"\n",
        "        Trains the classifier using the given training examples.\n",
        "\n",
        "        Args: \n",
        "            features: A feature matrix, where each row represents a text.\n",
        "\n",
        "            labels: A label vector, where each entry represents a label.\n",
        "        \"\"\"\n",
        "        self.clf.fit(features, labels)\n",
        "    \n",
        "    def predict(self, features: NDArray) -> NDArray:\n",
        "        \"\"\"\n",
        "        Makes predictions for each of the given examples.\n",
        "\n",
        "        Args:\n",
        "            features: A feature matrix, where each row represents a text.\n",
        "        Such matrices will typically be generated via TextToFeatures.\n",
        "        \n",
        "        Returns: \n",
        "            predictions: A prediction vector, where each entry represents a label.\n",
        "            predprob: A probability vector, where each entry represents the predicted probability of the corresponding label in the prediction vector. \n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        predictions = self.clf.predict(features)\n",
        "        predprob = self.clf.predict_proba(features)\n",
        "    \n",
        "        return predictions, predprob\n",
        "    \n",
        "    def code(self, train_features, test_features, train_labels):\n",
        "        \n",
        "        self.train(train_features, train_labels)\n",
        "        self.predicted_labels, self.predicted_probabilities = self.predict(test_features)\n",
        "        \n",
        "        return self.predicted_labels, self.predicted_probabilities\n",
        "    \n",
        "    def metrics(self, test_labels):\n",
        "        \"\"\"\n",
        "        Obtains evaluation metrics by comparing model predictions to original human coding on test data. \n",
        "        \"\"\"\n",
        "\n",
        "        accuracy = accuracy_score(test_labels, self.predicted_labels)\n",
        "        f1 = f1_score(test_labels, self.predicted_labels, pos_label=1)\n",
        "        precision = precision_score(test_labels, self.predicted_labels)\n",
        "        recall = recall_score(test_labels, self.predicted_labels)\n",
        "        kappa = cohen_kappa_score(test_labels, self.predicted_labels)\n",
        "        \n",
        "        return [accuracy, f1, precision, recall, kappa]\n",
        "\n",
        "def classify(classifier, data, eval_codes, train_set, test_set, method = ['pred']):\n",
        "    \"\"\"\n",
        "    Train a machine learning model to predict human codings of interest based on each training/test split.\n",
        "    \n",
        "    Args:\n",
        "        classifier: the machine learning model. \n",
        "        \n",
        "        eval_codes: the list of codes to be scaled, corresponding to the \"Codes\" column from the ATLAS.ti export file.\n",
        "        \n",
        "        train_set/test_set: the ids of interviews to use as training/test data. \n",
        "        \n",
        "        method: \"pred\" or \"eval\". \n",
        "                \n",
        "                - The \"pred\" method predicts codings on uncoded data without returning metrics. \n",
        "                - The \"eval\" method predicts codings on coded data and compare the predictions against original human codings. \n",
        "        \n",
        "    Returns:\n",
        "        predictions: the predicted probability of a code on a paragraph.\n",
        "        \n",
        "        metrics: a list of performance metrics the \"eval\" method generates. \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    predictions = pd.DataFrame({'code': [], 'test_set': [], 'p': []})\n",
        "    metrics = pd.DataFrame({'code': [], 'test_set': [], 'n':[], 'accuracy': [], 'f1': [], 'precision': [], 'recall': [],  \n",
        "                            'kappa': []})\n",
        "    \n",
        "    for code in eval_codes:\n",
        "        for train_ids, test_ids in zip(train_set, test_set):\n",
        "\n",
        "            train_data = data[data['Document'].isin([all_cases[id] for id in train_ids])]\n",
        "            test_data = data[-data['Document'].isin([all_cases[id] for id in train_ids])]\n",
        "\n",
        "            train_id = train_data.index.tolist()\n",
        "            test_id = test_data.index.tolist()\n",
        "\n",
        "            train_features = features[train_id]\n",
        "            test_features = features[test_id]\n",
        "\n",
        "            train_labels = train_data[code].values.tolist()\n",
        "            \n",
        "            predicted_labels, predicted_probabilities = classifier.code(train_features, test_features, train_labels)\n",
        "\n",
        "            predictions = predictions.append(pd.Series([code, test_ids] + [[x[1] for x in predicted_probabilities]], index = predictions.columns), ignore_index=True)\n",
        "\n",
        "            if method == 'eval':\n",
        "                test_labels = test_data[code].values.tolist()\n",
        "                metrics = metrics.append(pd.Series([code, test_ids, data.loc[data['Document'].isin([all_cases[id] for id in train_ids]), code].sum()] + classifier.metrics(test_labels), index = metrics.columns), ignore_index=True) \n",
        "            \n",
        "    return predictions, metrics\n",
        "\n",
        "predictions, metrics = classify(Classifier(), training, eval_codes, train_set, test_set, 'eval')\n",
        "\n",
        "pd.DataFrame({'N': training[eval_codes].sum()}).join(metrics.groupby('code')[['n', 'accuracy', 'f1', 'precision', 'recall', 'kappa']].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note\n",
        "\n",
        "_Remember the definition of recall and precision and the restaurant examples - the model is doing a particularly good job in casting a wide net and not missing too many orders - on average machine learning catches about 70% of all relevant paragraphs, which is not too far below the average human performance in qualitative coding._\n",
        "\n",
        "_As a tradeoff, it is not very precise and contains a lot of items - paragraphs - that you did not order, but we can easily fix it in our next step, because now instead of the whole 20k-paragraph dataset, we are looking at only about 20% of it._\n",
        "\n",
        "- _Recall: measures how many percentage of all relevant cases a model picks up in a classification task. Suppose you are in a restaurant, a waiter misses three out of four items you ordered has a recall of 0.25, and of course you want a waiter with higher recall!_\n",
        "\n",
        "- _Precision: measures how many percentage of cases a model picks up are actually relevant in a classification task. Suppose you are in a restaurant, your waiter brings to you four items, but three out of the four items are items that you didn't order. This waiter has a precision of 25%, and of course you want a waiter with higher precision!_ \n",
        "\n",
        "- _F-1: measures the overall performance of a machine learning model in classification tasks._\n",
        "\n",
        "_For more detail, see https://journals.sagepub.com/doi/10.1177/23780231211062345_"
      ],
      "metadata": {
        "id": "OkLaFM5xy5i1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part IV (OPTIONAL): Recoding"
      ],
      "metadata": {
        "id": "zZlKfUzwJSzo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4GLK0MSLgqr"
      },
      "source": [
        "Now that we have caught about 70% of all paragraphs that would have been coded as \"Educational Background\", we want to quickly review the results and filter out obivous errors - especially the irrelevant ones that the algorithm has mistaken to be \"Background\".\n",
        "\n",
        "This cell creates highly customized spreadsheets that include part of the original text that the algorithm has labeled as \"Background\". Researchers can then go through this list to correct any obvious _false positives_. \n",
        "\n",
        "In most cases, recoding machine predictions only takes a fraction of the time and effort required by full human coding, because the algorithm has filtered out the vast majority of \"irrelevant\" texts, as defined by _YOUR_ own coding.\n",
        "\n",
        "We explained this point in a recent piece [here](https://osf.io/preprints/socarxiv/gpr4n/). The figure below reveals the 'punchline' of our tests.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9QbbqrfLeJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5f30b24f-2ab9-41b3-f0e4-d820a285775b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Document Reference  Pred_Background Background?  \\\n",
              "1494         Patricia_Brown     19501         0.999971               \n",
              "9899        Vincente_Ortega    119695         0.999954               \n",
              "5250        Arminta_Harness     63468         0.999941               \n",
              "13879            Ben_Vester    161096         0.999926               \n",
              "8633         Arthur_McComas    104792         0.999921               \n",
              "...                     ...       ...              ...         ...   \n",
              "13279          Ralph_Strong    151383         0.500444               \n",
              "6817        Margaret_Kipilo     86791         0.500353               \n",
              "13821  Gottfried_Ungerboeck    159032         0.500263               \n",
              "6292            Milton_Kant     81923         0.500193               \n",
              "2482         Charles_Denton     34410         0.500134               \n",
              "\n",
              "                                                   Quote  \n",
              "1494   My father was William Madison Brown, and my mo...  \n",
              "9899   My father was in the hardware business. I have...  \n",
              "5250   Mother graduated from high school there, and D...  \n",
              "13879  I was born down in North Carolina in a little ...  \n",
              "8633   My father was a building manager. Both my pare...  \n",
              "...                                                  ...  \n",
              "13279  We had a little arc furnace and a copper cruci...  \n",
              "6817   No. I never remember saying anything. I don’t ...  \n",
              "13821  Was it a one year period you were in the milit...  \n",
              "6292   The Navy was not using television. I think tha...  \n",
              "2482   It was in Vallejo, California, right outside o...  \n",
              "\n",
              "[4880 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-987417c1-1afb-458c-8f84-75adaabb374d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Pred_Background</th>\n",
              "      <th>Background?</th>\n",
              "      <th>Quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>Patricia_Brown</td>\n",
              "      <td>19501</td>\n",
              "      <td>0.999971</td>\n",
              "      <td></td>\n",
              "      <td>My father was William Madison Brown, and my mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9899</th>\n",
              "      <td>Vincente_Ortega</td>\n",
              "      <td>119695</td>\n",
              "      <td>0.999954</td>\n",
              "      <td></td>\n",
              "      <td>My father was in the hardware business. I have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5250</th>\n",
              "      <td>Arminta_Harness</td>\n",
              "      <td>63468</td>\n",
              "      <td>0.999941</td>\n",
              "      <td></td>\n",
              "      <td>Mother graduated from high school there, and D...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13879</th>\n",
              "      <td>Ben_Vester</td>\n",
              "      <td>161096</td>\n",
              "      <td>0.999926</td>\n",
              "      <td></td>\n",
              "      <td>I was born down in North Carolina in a little ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8633</th>\n",
              "      <td>Arthur_McComas</td>\n",
              "      <td>104792</td>\n",
              "      <td>0.999921</td>\n",
              "      <td></td>\n",
              "      <td>My father was a building manager. Both my pare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13279</th>\n",
              "      <td>Ralph_Strong</td>\n",
              "      <td>151383</td>\n",
              "      <td>0.500444</td>\n",
              "      <td></td>\n",
              "      <td>We had a little arc furnace and a copper cruci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6817</th>\n",
              "      <td>Margaret_Kipilo</td>\n",
              "      <td>86791</td>\n",
              "      <td>0.500353</td>\n",
              "      <td></td>\n",
              "      <td>No. I never remember saying anything. I don’t ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13821</th>\n",
              "      <td>Gottfried_Ungerboeck</td>\n",
              "      <td>159032</td>\n",
              "      <td>0.500263</td>\n",
              "      <td></td>\n",
              "      <td>Was it a one year period you were in the milit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6292</th>\n",
              "      <td>Milton_Kant</td>\n",
              "      <td>81923</td>\n",
              "      <td>0.500193</td>\n",
              "      <td></td>\n",
              "      <td>The Navy was not using television. I think tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2482</th>\n",
              "      <td>Charles_Denton</td>\n",
              "      <td>34410</td>\n",
              "      <td>0.500134</td>\n",
              "      <td></td>\n",
              "      <td>It was in Vallejo, California, right outside o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4880 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-987417c1-1afb-458c-8f84-75adaabb374d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-987417c1-1afb-458c-8f84-75adaabb374d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-987417c1-1afb-458c-8f84-75adaabb374d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from numpy.ma.core import outerproduct\n",
        "from google.colab import files\n",
        "\n",
        "test_set = metrics.sort_values(['recall', 'f1'], ascending = False).groupby('code').nth(0)['test_set'].tolist()[0]\n",
        "train_set = list(set(range(len(all_cases)))-set(test_set))\n",
        "predictions, _ = classify(Classifier(), training, eval_codes, [train_set], [test_set])\n",
        "\n",
        "recode_set = test_set\n",
        "combine_codes = [0]\n",
        "\n",
        "sorting = [True]\n",
        "sorting_vars = [['Background']]\n",
        "\n",
        "pruning = [True]\n",
        "pruning_thresholds = [0.5]\n",
        "\n",
        "def gen_recode(data, predictions, all_cases, recode_set, combine_codes, sorting, pruning, sorting_vars = None, pruning_threshold = None):\n",
        "    \"\"\"\n",
        "    Export all machine-coded rows in several Excel spreadsheets that facilitate human reviewing and recoding. \n",
        "    \n",
        "    Args:\n",
        "        data: a DataFrame that stores the original training data (i.e. \"training\"). \n",
        "        \n",
        "        predictions: a DataFrame that stores a list of machine-generated codings on the target data for each code (i.e. \"predictions\"). \n",
        "        \n",
        "        all_cases: the ids of interviews to use as training/test data. \n",
        "\n",
        "        recode_set: a List of the ids of interviews to be reviewed and recoded. \n",
        "\n",
        "        combine_codes: a List that defines which codes are to be exported and recoded together in one spreadsheet. The number of unique values is the number of spreadsheets to be generated and codes that are assigned the same value will appear in the same spreadsheet\n",
        "\n",
        "        sorting: a List of boolean values (True or False) where sorting[i] defines whether spreadsheet[i] should be sorted by predicted probabilities or remain in chronological order. \n",
        "\n",
        "        sorting_vars: if sorting[i] = True, sorting_vars[i] defines by which code's predicted probabilities the whole spreadsheet will be sorted. \n",
        "        \n",
        "        pruning: a List of boolean values (True or False) where pruning[i] defines whether spreadsheet[i] should be pruned by predicted probabilities.\n",
        "\n",
        "        pruning_thresholds: if pruning[i] = True, pruning_thresholds[i] defines the threshold of pruning (rows with a predicted probability below the threshold will not appear in the recoding spreadsheet). \n",
        "        \n",
        "    Returns:\n",
        "        \n",
        "        spreadsheets: a list of DataFrames that each stores one recoding spreadsheet. \n",
        "    \n",
        "    \"\"\"\n",
        "    recode = data[data['Document'].isin([all_cases[id] for id in recode_set])][['Quote', 'Document', 'Reference']].reset_index(drop = True)\n",
        "    \n",
        "    for code in eval_codes:\n",
        "        #recode_set = best.loc[code]['test_set']\n",
        "        p = predictions.loc[(predictions['code'] == code) & (predictions['test_set'].apply(lambda x: x==recode_set))]['p'].values.tolist()[0]\n",
        "        col = pd.DataFrame({str(combine_codes[eval_codes.index(code)]) + '_P_' + code :p})\n",
        "        recode = recode.join(col)\n",
        "    \n",
        "    spreadsheets = []\n",
        "\n",
        "    for doc_id in range(max(combine_codes)+1):\n",
        "        out = recode[['Document', 'Reference']]\n",
        "        name = \"Pred_\"\n",
        "\n",
        "        rowids_to_keep = []\n",
        "\n",
        "        for col in (col for col in recode if col.startswith(str(doc_id))):\n",
        "\n",
        "            out = out.join(recode[[col]])\n",
        "\n",
        "            colname = col.rsplit('_',1)[1]\n",
        "\n",
        "            name = name + colname\n",
        "\n",
        "            out.rename(columns={col: name}, inplace=True)\n",
        "\n",
        "            out[colname+'?'] = ''\n",
        "\n",
        "            if pruning[doc_id] == True:\n",
        "                rowids_to_keep.append(out[name].index[out[name] >= pruning_threshold[doc_id]].tolist() )\n",
        "\n",
        "        out = out.join(recode[['Quote']])\n",
        "\n",
        "        if pruning[doc_id] == True:\n",
        "            out = out.iloc[list(set([item for sublist in rowids_to_keep for item in sublist]))]\n",
        "        \n",
        "        if sorting[doc_id] == True:\n",
        "            out = out.sort_values(by = [\"Pred_\" + v for v in sorting_vars[doc_id]], ascending = False)\n",
        "        else:\n",
        "            out = out.sort_index()\n",
        "        \n",
        "        spreadsheets.append(out)\n",
        "\n",
        "        # Uncommenting the following two lines will generate actual Excel files and download them to your local device. \n",
        "\n",
        "        #out.to_excel(name + \".xlsx\")\n",
        "        #files.download(name + \".xlsx\")\n",
        "\n",
        "    return spreadsheets\n",
        "\n",
        "recoding_spreadsheet = gen_recode(training, predictions, all_cases, recode_set, combine_codes, sorting, pruning, sorting_vars, pruning_thresholds)\n",
        "\n",
        "recoding_spreadsheet[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now a human researcher can quickly review all the paragraphs the algorithm finds to be potentially relevant to our \"Background\" code and check whether any paragraph is not. "
      ],
      "metadata": {
        "id": "ZoyhWpcB2TrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recoding_spreadsheet[0].iloc[0]['Quote']"
      ],
      "metadata": {
        "id": "N6XMOeFtRk49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recoding_spreadsheet[0].iloc[1]['Quote']"
      ],
      "metadata": {
        "id": "UC7eelygRogM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recoding_spreadsheet[0].iloc[-1]['Quote']"
      ],
      "metadata": {
        "id": "Bd7NwRGmRol8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a simple word cloud built from rows that our machine learning model thinks are relevant to our code \"Background\"! The bigger a word is, the more frequent it is in the text. "
      ],
      "metadata": {
        "id": "GIRJpeNCP7kB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part IV (OPTIONAL): Visualize"
      ],
      "metadata": {
        "id": "K1DhJOW0JnOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400, scale = 10).generate(recoding_spreadsheet[0]['Quote'].str.cat(sep=' '))\n",
        "plt.figure( figsize=(20,10) )\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0ZjTxJtXt9m",
        "outputId": "f7cd7a27-81d2-4bc5-bb5e-2f20a141768f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.21.6)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2510670e9e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwordcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecoding_spreadsheet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Quote'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'recoding_spreadsheet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part V: Export for External Analysis"
      ],
      "metadata": {
        "id": "ZP0wtr9MJs_S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtKZ7oPdMy7O"
      },
      "source": [
        "### Preparing for ATLAS.ti\n",
        "\n",
        "Once you have confirmed that the coding is adequate (and, if necessary, reviewed and recoded the machine-generated codings for obvious errors), you can use the function below to export the coded data in a special format that can then be reimported into ATLAS.ti. \n",
        "\n",
        "*This can also be integrated into other QDA software, analyzed in a spreadsheet, or python.*\n",
        "\n",
        "We add machine-generated and human-reviewed codings back to the original data (including all rows) in the original order. \n",
        "\n",
        "A tutorial can be found here. [link]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NtigcqjMs5O"
      },
      "outputs": [],
      "source": [
        "def reimport2ATLAS(full_data, recoded, recoded_set, recoded_cases):\n",
        "    for code in recoded_set:\n",
        "        recoded.loc[recoded[code].isna(), code] = recoded.loc[recoded[code].isna(), \"P_\"+code]\n",
        "        recoded[code] = recoded[code].apply(lambda x: x >= 0.5).astype(int)\n",
        "        full_data.merge(recoded[['Document', 'Reference', code]], on = ['Document', 'Reference'], how = 'left')\n",
        "   \n",
        "    code_list = [col for col in full_data.columns.tolist() if col not in ['Document', 'Reference', 'Quote', 'Quotation Content', 'Codes', 'Codes_Frozen','nan']] \n",
        "    \n",
        "    for i in range(len(full_data)):\n",
        "        if full_data.loc[i,\"Document\"] in all_cases:\n",
        "            for code in code_list:\n",
        "                if(full_data.loc[i, code] >= 0.5): full_data.loc[i,'Quotation Content'] = full_data.loc[i,'Quotation Content'] + ' ' + '#' + code\n",
        "        \n",
        "    full_data['idx'] = full_data.groupby('Document').cumcount()\n",
        "    full_data['p_idx'] = 'p' + full_data['idx'].astype(str)\n",
        "    full_pivot = full_data.pivot(index='Document',columns='p_idx', values = 'Quotation Content')\n",
        "    full_pivot = full_pivot.reindex(sorted(full_pivot.columns, key=lambda x: float(x[1:])), axis=1)\n",
        "    full_pivot.to_excel(\"Recoded_output_transformed_all_cases_all_codes.xlsx\")\n",
        "\n",
        "# recoded_set = [\"Background\"]\n",
        "# recoded = pd.read_excel(\"\")\n",
        "# reimport2ATLAS(original, recoded, recoded_set, all_cases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIyXowWDLaxp"
      },
      "source": [
        "## Appendix: Scraping Interview Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The interview data we use in this tutorial were scraped from The Institute of Electrical and Electronics Engineers History Center's [Engineering and Technology History Wiki](https://ethw.org/Oral-History:List_of_all_Oral_Histories), using the Python code below. \n",
        "\n",
        "Please note that no part of the data may be quoted for publication without the written permission of the Director of IEEE History Center. Request for permission to quote for publication should be addressed to the IEEE History Center Oral History Program, IEEE History Center, 445 Hoes Lane, Piscataway, NJ 08854 USA or ieee-history@ieee.org. "
      ],
      "metadata": {
        "id": "Jq9wXogTQ9mI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install necessary libraries"
      ],
      "metadata": {
        "id": "X4aRiwuywUMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!apt-get update \n",
        "!apt install chromium-chromedriver\n",
        "\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "metadata": {
        "id": "rxv1INobkm_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e47c0b34-b5d2-4b48-a321-ae8d2f30f1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 58.6 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 49.9 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.10 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 urllib3-1.26.10 wsproto-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 1,581 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [1 InRelease gpgv 1,581 B] [Waiting for headers] [Connecting to security.ubu\r0% [1 InRelease gpgv 1,581 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [85.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,302 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,526 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,900 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,332 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,063 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,105 kB]\n",
            "Fetched 12.6 MB in 20s (637 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 64 not upgraded.\n",
            "Need to get 89.8 MB of archives.\n",
            "After this operation, 302 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 101.0.4951.64-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 101.0.4951.64-0ubuntu0.18.04.1 [78.5 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 101.0.4951.64-0ubuntu0.18.04.1 [4,980 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 101.0.4951.64-0ubuntu0.18.04.1 [5,153 kB]\n",
            "Fetched 89.8 MB in 16s (5,655 kB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_101.0.4951.64-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the Table of Content"
      ],
      "metadata": {
        "id": "ngz8RAwzwcBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "driver.get(\"https://ethw.org/Oral-History:List_of_all_Oral_Histories\")\n",
        "content = driver.page_source\n",
        "soup = BeautifulSoup(content)\n",
        "\n",
        "links = []\n",
        "\n",
        "for link in soup.find_all('a', attrs={'href': re.compile(\"/Oral-History\")}):\n",
        "    links.append(link.get('href'))\n",
        "\n",
        "links.index(\"/Oral-History:Henry_B._Abajian\")\n",
        "\n",
        "links[48:]"
      ],
      "metadata": {
        "id": "uuUFfboxuhgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d68dc8-b7d0-477f-ea04-faaeb2728d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: use options instead of chrome_options\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/Oral-History:Henry_B._Abajian',\n",
              " '/Oral-History:Willis_Adcock',\n",
              " '/Oral-History:Michael_Adler',\n",
              " '/Oral-History:Norbert_Adler',\n",
              " '/Oral-History:Roberto_Aguilera',\n",
              " '/Oral-History:William_Ross_Aiken',\n",
              " '/Oral-History:Rachid_Alami',\n",
              " '/Oral-History:Charles_Alexander',\n",
              " '/Oral-History:Royal_P._Allaire',\n",
              " '/Oral-History:David_W._Allan',\n",
              " '/Oral-History:Frances_%22Fran%22_Allen',\n",
              " '/Oral-History:Robert_Ambrose',\n",
              " '/Oral-History:Brian_Anderson',\n",
              " '/Oral-History:Deborah_Anderson',\n",
              " '/Oral-History:W._Cleon_Anderson',\n",
              " '/Oral-History:Wes_Anderson',\n",
              " '/Oral-History:Eva_Andrei',\n",
              " '/Oral-History:Fred_Andrews',\n",
              " '/Oral-History:Bruce_Angwin',\n",
              " '/Oral-History:David_Anthony',\n",
              " '/Oral-History:Diran_Apelian',\n",
              " '/Oral-History:Frank_F._Aplan',\n",
              " '/Oral-History:Tatsuo_Arai',\n",
              " '/Oral-History:Michael_Arbib',\n",
              " '/Oral-History:Ronald_Arkin',\n",
              " '/Oral-History:Ken_Arnold',\n",
              " '/Oral-History:Lyn_Arscott',\n",
              " '/Oral-History:Robert_Arzbaecher',\n",
              " '/Oral-History:Minoru_Asada',\n",
              " '/Oral-History:Eric_Ash',\n",
              " '/Oral-History:William_Aspray',\n",
              " '/Oral-History:Karl_Astrom',\n",
              " '/Oral-History:Chris_Atkeson',\n",
              " '/Oral-History:Werner_F._Auerbacher',\n",
              " '/Oral-History:James_Aylor',\n",
              " '/Oral-History:Khalid_Aziz',\n",
              " '/Oral-History:Jacob_Baal-Schem',\n",
              " '/Oral-History:Albert_%22Les%22_Babb',\n",
              " '/Oral-History:Charles_Bachman',\n",
              " '/Oral-History:Henry_Bachman',\n",
              " '/Oral-History:Jean_Bacon',\n",
              " '/Oral-History:Betty_Lou_Bailey',\n",
              " '/Oral-History:Robert_Baim',\n",
              " '/Oral-History:Kenneth_T._Bainbridge',\n",
              " '/Oral-History:Ruzena_Bajcsy',\n",
              " '/Oral-History:Ruzena_Bajcsy_(2010)',\n",
              " '/Oral-History:Edythe_Baker',\n",
              " '/Oral-History:Earl_Bakken',\n",
              " '/Oral-History:Kavita_Bala',\n",
              " '/Oral-History:Jack_Balde',\n",
              " '/Oral-History:Christopher_Bale',\n",
              " '/Oral-History:B._Jayant_Baliga',\n",
              " '/Oral-History:Jens_Bang',\n",
              " '/Oral-History:Paul_Baran',\n",
              " '/Oral-History:C.E._Barrette',\n",
              " '/Oral-History:Lionel_Barthold',\n",
              " '/Oral-History:Jean_Bartik',\n",
              " '/Oral-History:Thomas_Bartlett',\n",
              " '/Oral-History:James_Bassingthwaighte',\n",
              " '/Oral-History:Eleanor_Baum',\n",
              " '/Oral-History:Arnold_Beck',\n",
              " '/Oral-History:George_Bekey',\n",
              " '/Oral-History:Maurice_Bellanger',\n",
              " '/Oral-History:Ottorino_Beltrami',\n",
              " '/Oral-History:Ralph_Benjamin',\n",
              " '/Oral-History:Alain_Bensoussan',\n",
              " '/Oral-History:Leo_Beranek_(1996)',\n",
              " '/Oral-History:Leo_Beranek_(2005)',\n",
              " '/Oral-History:Fran_Berman',\n",
              " '/Oral-History:Mary_Lee_Berners-Lee',\n",
              " '/Oral-History:Tim_Berners-Lee',\n",
              " '/Oral-History:Harold_H._Beverage',\n",
              " '/Oral-History:Lois_Bey',\n",
              " '/Oral-History:Harry_Bhadeshia',\n",
              " '/Oral-History:Roshan_Bhappu',\n",
              " '/Oral-History:Rene_Bidard',\n",
              " '/Oral-History:Gottfried_Biegelmeier',\n",
              " '/Oral-History:Harold_S._Black',\n",
              " '/Oral-History:Tom_Blasingame',\n",
              " '/Oral-History:Woodrow_Wilson_Bledsoe',\n",
              " '/Oral-History:Ron_Blicq',\n",
              " '/Oral-History:Herman_Blinchikoff',\n",
              " '/Oral-History:Martin_Bloch',\n",
              " '/Oral-History:Nicolaas_Bloembergen',\n",
              " '/Oral-History:Jim_Bobrow',\n",
              " '/Oral-History:Bob_Bolles',\n",
              " '/Oral-History:Susan_Bond',\n",
              " '/Oral-History:Gary_Boone',\n",
              " '/Oral-History:Joseph_Bordogna',\n",
              " '/Oral-History:Anita_Borg',\n",
              " '/Oral-History:Berthold_Bosch',\n",
              " '/Oral-History:James_Boyd',\n",
              " '/Oral-History:George_Brewster',\n",
              " '/Oral-History:Jim_Brill',\n",
              " '/Oral-History:Yvonne_Brill',\n",
              " '/Oral-History:Robert_Briskman',\n",
              " '/Oral-History:Patricia_Brown',\n",
              " '/Oral-History:Herbert_Bruch',\n",
              " '/Oral-History:Per_Bruel',\n",
              " '/Oral-History:Herman_Bruyninckx',\n",
              " '/Oral-History:Janis_Bubenko',\n",
              " '/Oral-History:Merrill_Buckley',\n",
              " '/Oral-History:Richard_L._Bullock',\n",
              " '/Oral-History:Richard_Burden',\n",
              " '/Oral-History:Joel_Burdick',\n",
              " '/Oral-History:Arthur_Burks',\n",
              " '/Oral-History:C._Sidney_Burrus',\n",
              " '/Oral-History:Julian_Bussgang',\n",
              " '/Oral-History:Joe_Butler',\n",
              " '/Oral-History:Joe_Cahalan',\n",
              " '/Oral-History:James_Thomas_Cain',\n",
              " '/Oral-History:Betty_Campbell',\n",
              " '/Oral-History:Rosemary_Candlin',\n",
              " '/Oral-History:Norm_Caplan',\n",
              " '/Oral-History:Francesco_Carassa',\n",
              " '/Oral-History:Mario_W._Cardullo',\n",
              " '/Oral-History:Brian_Carlisle',\n",
              " '/Oral-History:Emily_Carter',\n",
              " '/Oral-History:Alicia_Casals',\n",
              " '/Oral-History:Jack_Casazza',\n",
              " '/Oral-History:Sharon_Cascadden',\n",
              " '/Oral-History:Vinton_Cerf',\n",
              " '/Oral-History:John_Chadwick',\n",
              " '/Oral-History:Milton_Chaffee',\n",
              " '/Oral-History:Britton_Chance',\n",
              " '/Oral-History:Carl_Chang',\n",
              " '/Oral-History:Robert_Chapuis',\n",
              " '/Oral-History:Raja_Chatila',\n",
              " '/Oral-History:John_C._Chato',\n",
              " '/Oral-History:Li-Chyong_Chen',\n",
              " '/Oral-History:Martin_Chenevert',\n",
              " '/Oral-History:Shu_Chien',\n",
              " '/Oral-History:Marvin_Chodorow',\n",
              " '/Oral-History:Howie_Choset',\n",
              " '/Oral-History:Fan_Chung-Graham',\n",
              " '/Oral-History:John_Cioffi',\n",
              " '/Oral-History:Jacques_Clade',\n",
              " '/Oral-History:Judy_Clapp',\n",
              " '/Oral-History:Yvonne_Young_Clark_and_Carol_Lawson',\n",
              " '/Oral-History:John_Coales',\n",
              " '/Oral-History:Clark_Colton',\n",
              " '/Oral-History:Charles_Concordia',\n",
              " '/Oral-History:Harry_M._Conger,_III',\n",
              " '/Oral-History:David_A._Conner',\n",
              " '/Oral-History:Anthony_Constantinides',\n",
              " '/Oral-History:James_W._Cooley',\n",
              " '/Oral-History:Betty_Cooper',\n",
              " '/Oral-History:Lois_Cooper',\n",
              " '/Oral-History:Warren_Cooper',\n",
              " '/Oral-History:Susan_Coppersmith',\n",
              " '/Oral-History:Peter_Corke',\n",
              " '/Oral-History:Andrew_Corry',\n",
              " '/Oral-History:William_E._Cory',\n",
              " '/Oral-History:Wayne_Cowell',\n",
              " '/Oral-History:Donald_Cox',\n",
              " '/Oral-History:John_Craig',\n",
              " '/Oral-History:L._Eric_Cross',\n",
              " '/Oral-History:JC_Cunha',\n",
              " '/Oral-History:David_Curry',\n",
              " '/Oral-History:C._Chapin_Cutler',\n",
              " '/Oral-History:Luigi_Dadda',\n",
              " '/Oral-History:Ron_Daniel',\n",
              " '/Oral-History:Stella_Lawrence_Daniels',\n",
              " '/Oral-History:Paolo_Dario',\n",
              " '/Oral-History:Lee_Davenport',\n",
              " '/Oral-History:Martin_Davis',\n",
              " '/Oral-History:Edward_de_Laet',\n",
              " '/Oral-History:Stacey_DelVecchio_and_Margo_Bubb',\n",
              " '/Oral-History:Stacey_DelVecchio_(2010)',\n",
              " '/Oral-History:Stanley_Dempsey',\n",
              " '/Oral-History:Ernst_Denert',\n",
              " '/Oral-History:Charles_Denton',\n",
              " '/Oral-History:Marjorie_%22Marge%22_Devaney',\n",
              " '/Oral-History:Ernst_Dickmanns',\n",
              " '/Oral-History:Miwako_Doi',\n",
              " '/Oral-History:Jean_Dollimore',\n",
              " '/Oral-History:Howard_Doolittle',\n",
              " '/Oral-History:Herbert_Doring',\n",
              " '/Oral-History:Joseph_Douglas',\n",
              " '/Oral-History:Rudolf_Drabek',\n",
              " '/Oral-History:Mildred_Dresselhaus',\n",
              " '/Oral-History:Andrew_Drozd',\n",
              " '/Oral-History:William_G._Duff',\n",
              " '/Oral-History:Robert_(Bob)_Duggan,_Jr.',\n",
              " '/Oral-History:Bonnie_Dunbar',\n",
              " '/Oral-History:Sajjad_Durrani',\n",
              " '/Oral-History:Harriet_G._Dutka',\n",
              " '/Oral-History:Robert_Dwight',\n",
              " '/Oral-History:James_Early',\n",
              " '/Oral-History:Murray_Eden',\n",
              " '/Oral-History:Bruce_A._Eisenstein',\n",
              " '/Oral-History:Charles_Eldon',\n",
              " '/Oral-History:Margaret_Eller',\n",
              " '/Oral-History:Gerald_Engel',\n",
              " '/Oral-History:Joel_Engel',\n",
              " '/Oral-History:Irving_Engelson',\n",
              " '/Oral-History:Lloyd_Espenschied',\n",
              " '/Oral-History:Thelma_Estrin',\n",
              " '/Oral-History:Thelma_Estrin_(2002)',\n",
              " '/Oral-History:Thelma_Estrin_(2006)',\n",
              " '/Oral-History:Hong_Eu',\n",
              " '/Oral-History:Bruce_W._Everitt',\n",
              " '/Oral-History:Walter_Ewanus',\n",
              " '/Oral-History:Federico_Faggin',\n",
              " '/Oral-History:Tom_Falkie',\n",
              " '/Oral-History:Alma_Martinez_Fallon',\n",
              " '/Oral-History:Wayne_Fegely',\n",
              " '/Oral-History:Elizabeth_%22Jake%22_Feinler',\n",
              " '/Oral-History:Lyle_Feisel',\n",
              " '/Oral-History:Gabriel_Ferrate',\n",
              " '/Oral-History:Alfred_Fettweis',\n",
              " '/Oral-History:Barbara_A._Filas',\n",
              " '/Oral-History:Ray_Findlay',\n",
              " '/Oral-History:Bernard_Finn',\n",
              " '/Oral-History:Joseph_Fischer',\n",
              " '/Oral-History:Ren%C3%A9_Fl%C3%BCkiger',\n",
              " '/Oral-History:James_L._Flanagan',\n",
              " '/Oral-History:Steward_Flaschen',\n",
              " '/Oral-History:Merton_C._Flemings',\n",
              " '/Oral-History:Ann_Fletcher',\n",
              " '/Oral-History:Virgilio_Floriani',\n",
              " '/Oral-History:Charles_Flurscheim',\n",
              " '/Oral-History:Art_Fong',\n",
              " '/Oral-History:Terry_Fong',\n",
              " '/Oral-History:Jodi_Forlizzi',\n",
              " '/Oral-History:G._David_Forney',\n",
              " '/Oral-History:Ted_Foster',\n",
              " '/Oral-History:Evelyn_Fowler',\n",
              " '/Oral-History:Ted_Frankiewicz',\n",
              " '/Oral-History:Robert_C._Freas',\n",
              " '/Oral-History:Roy_Freed',\n",
              " '/Oral-History:Herbert_Freeman',\n",
              " '/Oral-History:Herbert_Freyhardt',\n",
              " '/Oral-History:Vladimir_Fridkin',\n",
              " '/Oral-History:Robert_Friedel',\n",
              " '/Oral-History:Hugo_Fruehauf',\n",
              " '/Oral-History:Douglas_W._Fuerstenau',\n",
              " '/Oral-History:Tetsuo_Fujimura',\n",
              " '/Oral-History:Den_Fujita',\n",
              " '/Oral-History:Eiichi_Fukada',\n",
              " '/Oral-History:Toshio_Fukuda',\n",
              " '/Oral-History:Leonard_Fuller',\n",
              " '/Oral-History:Bert_Fung',\n",
              " '/Oral-History:Sadaoki_Furui',\n",
              " '/Oral-History:Anita_Gale',\n",
              " '/Oral-History:Uzia_Galil',\n",
              " '/Oral-History:Robert_Gallager',\n",
              " '/Oral-History:Robert_Galvin',\n",
              " '/Oral-History:Karl_Ganzhorn',\n",
              " '/Oral-History:Oscar_Garcia',\n",
              " '/Oral-History:Wanda_Gass',\n",
              " '/Oral-History:Gus_Gaynor',\n",
              " '/Oral-History:Paolo_Gazzana-Priaroggia',\n",
              " '/Oral-History:Leslie_Geddes',\n",
              " '/Oral-History:Ron_Gedney',\n",
              " '/Oral-History:Virginia_Gerdes',\n",
              " '/Oral-History:David_Geselowitz',\n",
              " '/Oral-History:Ivan_A._Getting_(1991)',\n",
              " '/Oral-History:Ivan_A._Getting_(1995)',\n",
              " '/Oral-History:James_Gibbons',\n",
              " '/Oral-History:Betty_Gibbs',\n",
              " '/Oral-History:Sam_Gibbs',\n",
              " '/Oral-History:Juan_Gilbert',\n",
              " '/Oral-History:Dorothy_Gillette',\n",
              " '/Oral-History:Clinton_Gilliland',\n",
              " '/Oral-History:Edward_Ginzton',\n",
              " '/Oral-History:Joseph_Giordmaine',\n",
              " '/Oral-History:Natalie_Givans',\n",
              " '/Oral-History:Mike_Glazer',\n",
              " '/Oral-History:Roberta_Gleiter',\n",
              " '/Oral-History:Frank_W._Godsey',\n",
              " '/Oral-History:Adolf_Goetzberger',\n",
              " '/Oral-History:Ben_Gold',\n",
              " '/Oral-History:Adele_Goldberg',\n",
              " '/Oral-History:Ken_Goldberg',\n",
              " '/Oral-History:Alfred_N._Goldsmith',\n",
              " '/Oral-History:Thomas_Goldsmith',\n",
              " '/Oral-History:Gene_Golub',\n",
              " '/Oral-History:Eugene_Gordon',\n",
              " '/Oral-History:Ruth_Gordon',\n",
              " '/Oral-History:Judith_Gorman',\n",
              " '/Oral-History:Dimitry_Grabbe',\n",
              " '/Oral-History:Lois_Graham',\n",
              " '/Oral-History:Martin_Graham',\n",
              " '/Oral-History:Susan_Graham',\n",
              " '/Oral-History:John_Granger',\n",
              " '/Oral-History:Robert_M._Gray_(1991)',\n",
              " '/Oral-History:Robert_M._Gray_(1998)',\n",
              " '/Oral-History:Wilson_Greatbatch',\n",
              " '/Oral-History:Michael_Green',\n",
              " '/Oral-History:Paul_Green',\n",
              " '/Oral-History:John_Gregory',\n",
              " '/Oral-History:William_Gretsch',\n",
              " '/Oral-History:David_Alan_Grier',\n",
              " '/Oral-History:David_Gries',\n",
              " '/Oral-History:Denise_Griffin',\n",
              " '/Oral-History:Alain_Gringarten',\n",
              " '/Oral-History:Deborah_Grubbe_and_Jim_Porter',\n",
              " '/Oral-History:Jonathan_Grudin',\n",
              " '/Oral-History:John_Guarrera',\n",
              " '/Oral-History:Klaus_Gueldenpfennig',\n",
              " '/Oral-History:Vince_Gulden',\n",
              " '/Oral-History:Yury_Gulyaev',\n",
              " '/Oral-History:Satya_Gupta',\n",
              " '/Oral-History:Abraham_H._Haddad',\n",
              " '/Oral-History:Norihiro_Hagita',\n",
              " '/Oral-History:Lois_Haibt',\n",
              " '/Oral-History:Robert_N._Hall',\n",
              " '/Oral-History:Clark_A._Hamilton',\n",
              " '/Oral-History:Ki_Sun_Han',\n",
              " '/Oral-History:Daniel_Hang',\n",
              " '/Oral-History:Don_Hannegan',\n",
              " '/Oral-History:Edwin_Harder',\n",
              " '/Oral-History:Keld_Harder',\n",
              " '/Oral-History:Ann_Hardy',\n",
              " '/Oral-History:Arminta_Harness',\n",
              " '/Oral-History:Charles_Harper',\n",
              " '/Oral-History:Buddy_Harris',\n",
              " '/Oral-History:Leonard_Harris',\n",
              " '/Oral-History:Richard_Harris',\n",
              " '/Oral-History:Juris_Hartmanis',\n",
              " '/Oral-History:John_F._Havard',\n",
              " '/Oral-History:Paula_Hawthorn',\n",
              " '/Oral-History:Izuo_Hayashi',\n",
              " '/Oral-History:Peter_C._Hayes',\n",
              " '/Oral-History:Floyd_Hayhurst',\n",
              " '/Oral-History:Byron_Haynes',\n",
              " '/Oral-History:Gwen_Hays',\n",
              " '/Oral-History:Marlene_Hazle',\n",
              " '/Oral-History:Fred_Heath',\n",
              " '/Oral-History:Siegfried_S._Hecker',\n",
              " '/Oral-History:Don_Heirman',\n",
              " '/Oral-History:Martin_Hellman',\n",
              " '/Oral-History:Bobby_Hersom',\n",
              " '/Oral-History:William_Hewlett',\n",
              " '/Oral-History:Maggie_Hickel_and_Katie_Peterson',\n",
              " '/Oral-History:Clarence_Nichols_Hickman',\n",
              " '/Oral-History:James_Hillier',\n",
              " '/Oral-History:Shigeo_Hirose',\n",
              " '/Oral-History:Gerd_Hirzinger',\n",
              " '/Oral-History:Albert_Hoagland',\n",
              " '/Oral-History:Wallace_Hoff',\n",
              " '/Oral-History:H._Robert_Hofmann',\n",
              " '/Oral-History:Stephen_Holditch',\n",
              " '/Oral-History:John_Hollerbach',\n",
              " '/Oral-History:Ralph_Hollis',\n",
              " '/Oral-History:Beth_Holloway',\n",
              " '/Oral-History:Nick_Holonyak',\n",
              " '/Oral-History:Knud_Holst',\n",
              " '/Oral-History:Karl_Honaman',\n",
              " '/Oral-History:Ivy_Hooks',\n",
              " '/Oral-History:Dan_Hoolihan',\n",
              " '/Oral-History:Don_Hooper',\n",
              " '/Oral-History:Sara_Hornby',\n",
              " '/Oral-History:Roland_N._Horne',\n",
              " '/Oral-History:Mel_Hotz',\n",
              " '/Oral-History:Ayanna_Howard',\n",
              " '/Oral-History:Stanley_M._Howard',\n",
              " '/Oral-History:Thomas_Huang',\n",
              " '/Oral-History:Todd_Hubing',\n",
              " '/Oral-History:Roger_Hull',\n",
              " '/Oral-History:Kathy_Humphry',\n",
              " '/Oral-History:C.A._Hutchinson',\n",
              " '/Oral-History:Seth_Hutchinson',\n",
              " '/Oral-History:Jennie_S._Hwang',\n",
              " '/Oral-History:Hirochika_Inoue',\n",
              " '/Oral-History:Eleanor_Ireland',\n",
              " '/Oral-History:James_Isaak',\n",
              " '/Oral-History:Hiroshi_Ishiguro',\n",
              " '/Oral-History:Fumitada_Itakura',\n",
              " '/Oral-History:Yukikazu_Iwasa',\n",
              " '/Oral-History:Tatsuo_Izawa',\n",
              " '/Oral-History:Irwin_Jacobs',\n",
              " '/Oral-History:Joan_Leamy_James',\n",
              " '/Oral-History:Dov_Jaron',\n",
              " '/Oral-History:Ray_Jarvis',\n",
              " '/Oral-History:George_A._Jedenoff',\n",
              " '/Oral-History:Suzanne_Jenniches_(2003)',\n",
              " '/Oral-History:F._Suzanne_Jenniches',\n",
              " '/Oral-History:Suzanne_Jenniches',\n",
              " '/Oral-History:Jacob_Jensen',\n",
              " '/Oral-History:Amos_Joel_(1992)',\n",
              " '/Oral-History:Amos_Joel_(1993)',\n",
              " '/Oral-History:Rudy_Joenk',\n",
              " '/Oral-History:Elya_Joffe',\n",
              " '/Oral-History:Richard_J._Johns',\n",
              " '/Oral-History:Barbara_Crawford_Johnson',\n",
              " '/Oral-History:Barry_Johnson',\n",
              " '/Oral-History:Lawrence_Johnston',\n",
              " '/Oral-History:G._Frank_Joklik',\n",
              " '/Oral-History:Karen_Sp%C3%A4rck_Jones',\n",
              " '/Oral-History:William_Jones',\n",
              " '/Oral-History:Hilary_Kahn',\n",
              " '/Oral-History:Robert_Kahn',\n",
              " '/Oral-History:Thomas_Kailath',\n",
              " '/Oral-History:James_Kaiser',\n",
              " '/Oral-History:Laurel_Kaleda',\n",
              " '/Oral-History:Samuel_Kalow',\n",
              " '/Oral-History:Makoto_Kaneko',\n",
              " '/Oral-History:In-Ku_Kang',\n",
              " '/Oral-History:Jin_Ku_Kang',\n",
              " '/Oral-History:Ki_Dong_Kang',\n",
              " '/Oral-History:Sung_Mo_(Steve)_Kang',\n",
              " '/Oral-History:Milton_Kant',\n",
              " '/Oral-History:Charles_Kao',\n",
              " '/Oral-History:Frederic_Kaplan',\n",
              " '/Oral-History:Mitchell_Kapor',\n",
              " '/Oral-History:Gunther_Karger',\n",
              " '/Oral-History:Michael_Karmis',\n",
              " '/Oral-History:Walter_Karplus',\n",
              " '/Oral-History:Rangachar_Kasturi',\n",
              " '/Oral-History:Katsutaro_Kataoka',\n",
              " '/Oral-History:J._Lawrence_Katz',\n",
              " '/Oral-History:Lydia_Kavraki',\n",
              " '/Oral-History:Myron_Kayton',\n",
              " '/Oral-History:Kenji_Kazato_and_Kazuo_Ito',\n",
              " '/Oral-History:Arthur_C._Keller',\n",
              " '/Oral-History:Laurie_Keller',\n",
              " '/Oral-History:Jack_Kern',\n",
              " '/Oral-History:Warren_A._Kesselman',\n",
              " '/Oral-History:Oussama_Khatib',\n",
              " '/Oral-History:Pradeep_Khosla',\n",
              " '/Oral-History:Sara_Kiesler',\n",
              " '/Oral-History:Nobutoshi_Kihara',\n",
              " '/Oral-History:Makoto_Kikuchi',\n",
              " '/Oral-History:Jack_Kilby',\n",
              " '/Oral-History:Lee_Kilgore',\n",
              " '/Oral-History:Jae_Kyoon_Kim',\n",
              " '/Oral-History:Yong_Sun_Kim',\n",
              " '/Oral-History:Dieter_Kind',\n",
              " '/Oral-History:Alex_King',\n",
              " '/Oral-History:Archie_King',\n",
              " '/Oral-History:John_King',\n",
              " '/Oral-History:Willis_King',\n",
              " '/Oral-History:Margaret_Kipilo',\n",
              " '/Oral-History:Richard_Kirby',\n",
              " '/Oral-History:Mary_Kircher',\n",
              " '/Oral-History:Viggo_Kjaer',\n",
              " '/Oral-History:Richard_Klafter',\n",
              " '/Oral-History:Leonard_Kleinrock',\n",
              " '/Oral-History:Ron_Kline',\n",
              " '/Oral-History:C._Raymond_Knight',\n",
              " '/Oral-History:Koji_Kobayashi',\n",
              " '/Oral-History:Richard_Koch',\n",
              " '/Oral-History:Herwig_Kogelnik',\n",
              " '/Oral-History:Petar_Kokotovic',\n",
              " '/Oral-History:Petar_Kokotovic_(2011)',\n",
              " '/Oral-History:Jana_Kosecka',\n",
              " '/Oral-History:Kazuhiro_Kosuge',\n",
              " '/Oral-History:Danica_Kragic',\n",
              " '/Oral-History:Arthur_Krener',\n",
              " '/Oral-History:Hans_Kretz',\n",
              " '/Oral-History:Norman_B._Krim_(1984)',\n",
              " '/Oral-History:Herbert_Kroemer',\n",
              " '/Oral-History:Fikri_Kuchuk',\n",
              " '/Oral-History:David_Kuck',\n",
              " '/Oral-History:Ihor_A._Kunasz',\n",
              " '/Oral-History:Chung-Chieh_Jay_Kuo',\n",
              " '/Oral-History:Robert_Kyhl',\n",
              " '/Oral-History:Yoshihiro_Kyotani',\n",
              " '/Oral-History:Edward_F._Labuda',\n",
              " '/Oral-History:Larry_Lake',\n",
              " '/Oral-History:Ken_Laker',\n",
              " '/Oral-History:Susan_K._(Kathy)_Land',\n",
              " '/Oral-History:William_Lang',\n",
              " '/Oral-History:Bill_Langer',\n",
              " '/Oral-History:Erich_Langer',\n",
              " '/Oral-History:Pierre_Lapostolle',\n",
              " '/Oral-History:Robert_E._Larson',\n",
              " '/Oral-History:Jay_Lathrop',\n",
              " '/Oral-History:Jean-Paul_Laumond',\n",
              " '/Oral-History:Elizabeth_Laverick',\n",
              " '/Oral-History:Enrique_J._Lavernia',\n",
              " '/Oral-History:Harold_B._Law',\n",
              " '/Oral-History:Patricia_Law_and_Christine_Law',\n",
              " '/Oral-History:Robert_Lawrence',\n",
              " '/Oral-History:Benjamin_Lax',\n",
              " '/Oral-History:Peggy_Layne_(2010-1)',\n",
              " '/Oral-History:Peggy_Layne_(2010-2)',\n",
              " '/Oral-History:Peggy_Layne_and_Gail_Mattson',\n",
              " '/Oral-History:Jean_Lebel',\n",
              " '/Oral-History:Ernst_Lederer',\n",
              " '/Oral-History:Daniel_Lee',\n",
              " '/Oral-History:J._Kwon_Lee',\n",
              " '/Oral-History:Robert_G._H._Lee',\n",
              " '/Oral-History:David_Leeson',\n",
              " '/Oral-History:Meir_Lehman',\n",
              " '/Oral-History:Gerard_Lehmann',\n",
              " '/Oral-History:Humboldt_W._Leverenz',\n",
              " '/Oral-History:Judah_Levine',\n",
              " '/Oral-History:Moises_Levy',\n",
              " '/Oral-History:Clayton_Lewis_(Nov_2020)',\n",
              " '/Oral-History:Clayton_Lewis_(Dec_2020)',\n",
              " '/Oral-History:Frank_Lewis',\n",
              " '/Oral-History:Peter_Lewis',\n",
              " '/Oral-History:Ta_M._Li',\n",
              " '/Oral-History:Heather_Liddell',\n",
              " '/Oral-History:Michael_Lightner',\n",
              " '/Oral-History:Joseph_V._Lillie',\n",
              " '/Oral-History:Barbara_Liskov_(1991)',\n",
              " '/Oral-History:Barbara_Liskov_(2001)',\n",
              " '/Oral-History:Bede_Liu',\n",
              " '/Oral-History:Lennart_Ljung',\n",
              " '/Oral-History:Anna_Longobardo',\n",
              " '/Oral-History:Antonio_Luque_Lopez',\n",
              " '/Oral-History:Gillian_Lovegrove',\n",
              " '/Oral-History:James_Lovell',\n",
              " '/Oral-History:Donald_Lowden',\n",
              " '/Oral-History:J._David_Lowell',\n",
              " '/Oral-History:Raymond_L._Lowrie',\n",
              " '/Oral-History:Tomas_Lozano-Perez',\n",
              " '/Oral-History:Anne_Lucietto_and_Ledo_Lucietto',\n",
              " '/Oral-History:Robert_Lucky',\n",
              " '/Oral-History:George_Luxbacher',\n",
              " '/Oral-History:Theodore_F._Lyon',\n",
              " '/Oral-History:J._Ross_Macdonald',\n",
              " '/Oral-History:Allison_Machtemes_Lunde',\n",
              " '/Oral-History:Carol_G._Maclennan',\n",
              " '/Oral-History:Diana_Madden',\n",
              " '/Oral-History:Charles_Maerfeld',\n",
              " '/Oral-History:Alexis_P._Malozemoff',\n",
              " '/Oral-History:Plato_Malozemoff',\n",
              " '/Oral-History:Ramalatha_Marimuthu',\n",
              " '/Oral-History:Hans_Marko',\n",
              " '/Oral-History:Margaret_Marrs',\n",
              " '/Oral-History:Matt_Mason',\n",
              " '/Oral-History:Warren_P._Mason',\n",
              " '/Oral-History:Thaddeus_Massalski',\n",
              " '/Oral-History:James_L._Massey',\n",
              " '/Oral-History:Earl_Masterson',\n",
              " '/Oral-History:Robert_Mates',\n",
              " '/Oral-History:David_K._Matlock',\n",
              " '/Oral-History:Larry_Matthies',\n",
              " '/Oral-History:Gail_Mattson_(2011)',\n",
              " '/Oral-History:William_C._Maurer',\n",
              " '/Oral-History:Joseph_Maxfield',\n",
              " '/Oral-History:Ferdy_Mayer',\n",
              " '/Oral-History:John_Mayo',\n",
              " '/Oral-History:Naomi_McAfee_(2003)',\n",
              " '/Oral-History:Naomi_McAfee',\n",
              " '/Oral-History:Naomi_McAfee_(2010)',\n",
              " '/Oral-History:John_McCarthy',\n",
              " '/Oral-History:Mary_McCarthy',\n",
              " '/Oral-History:Arthur_McComas',\n",
              " '/Oral-History:Walter_McFall',\n",
              " '/Oral-History:Ronald_McFarlan',\n",
              " '/Oral-History:Bob_McGhee',\n",
              " '/Oral-History:Donald_H._McLaughlin',\n",
              " '/Oral-History:Alexander_McLean',\n",
              " '/Oral-History:James_McNaul',\n",
              " '/Oral-History:John_McPherson',\n",
              " '/Oral-History:Frank_Woods_McQuiston,_Jr.',\n",
              " '/Oral-History:Wolfgang_Mecklenbrauker',\n",
              " '/Oral-History:Nathan_Meehan',\n",
              " '/Oral-History:Mary_Tsingou_Menzel',\n",
              " '/Oral-History:Lou_Meren',\n",
              " '/Oral-History:Edward_Merrill',\n",
              " '/Oral-History:Russell_Mersereau',\n",
              " '/Oral-History:David_G._Messerschmitt',\n",
              " '/Oral-History:Robert_Metcalfe',\n",
              " '/Oral-History:David_Middleton_(2000)',\n",
              " '/Oral-History:David_Middleton_(2007)',\n",
              " '/Oral-History:Julian_Z._Millar',\n",
              " '/Oral-History:Judith_Mills',\n",
              " '/Oral-History:Dejan_Milojicic',\n",
              " '/Oral-History:Laurence_Milstein',\n",
              " '/Oral-History:Jerry_B._Minter',\n",
              " '/Oral-History:Max_Mintz',\n",
              " '/Oral-History:Jennifer_Miskimins',\n",
              " '/Oral-History:Sanjit_Mitra',\n",
              " '/Oral-History:Toshio_Mitsui',\n",
              " '/Oral-History:John_Moll',\n",
              " '/Oral-History:Andrew_R._Molnar',\n",
              " '/Oral-History:Francesco_Mondada',\n",
              " '/Oral-History:Carl_Montgomery',\n",
              " '/Oral-History:Gordon_Earl_Moore',\n",
              " '/Oral-History:Louis_F._Moose',\n",
              " '/Oral-History:Roland_Moreau',\n",
              " '/Oral-History:Fusao_Mori',\n",
              " '/Oral-History:Dorothy_Morris',\n",
              " '/Oral-History:A._Stephen_Morse',\n",
              " '/Oral-History:Pamela_%22Pam%22_Morton',\n",
              " '/Oral-History:Charles_W._Mueller',\n",
              " '/Oral-History:K._Alex_M%C3%BCller',\n",
              " '/Oral-History:James_Mulligan',\n",
              " '/Oral-History:Robert_Mumma',\n",
              " '/Oral-History:Saburo_Muroga',\n",
              " '/Oral-History:John_Murphy',\n",
              " '/Oral-History:Richard_Murray',\n",
              " '/Oral-History:Nancy_Musick',\n",
              " '/Oral-History:Hans_Musmann',\n",
              " '/Oral-History:Troy_Nagle',\n",
              " '/Oral-History:Radhika_Nagpal',\n",
              " '/Oral-History:Tsuneo_Nakahara',\n",
              " '/Oral-History:Heitaro_Nakajima',\n",
              " '/Oral-History:Shigeru_Nakajima',\n",
              " '/Oral-History:Frederik_Nebeker',\n",
              " '/Oral-History:Brad_Nelson',\n",
              " '/Oral-History:Jean-Daniel_Nicoud',\n",
              " '/Oral-History:John_%22Jack%22_Nieberding',\n",
              " '/Oral-History:Nils_Nilsson',\n",
              " '/Oral-History:Kazuhiko_Nishi',\n",
              " '/Oral-History:Takao_Nishitani',\n",
              " '/Oral-History:A._Michael_Noll',\n",
              " '/Oral-History:Shauna_Noonan',\n",
              " '/Oral-History:Illah_Nourbakhsh',\n",
              " '/Oral-History:Robert_N._Noyce',\n",
              " '/Oral-History:Herb_Nunnally',\n",
              " '/Oral-History:Cyril_T._O%27Connor',\n",
              " '/Oral-History:Jun_Ho_Oh',\n",
              " '/Oral-History:Russel_S._Ohl',\n",
              " '/Oral-History:Allison_Okamura',\n",
              " '/Oral-History:Takanori_Okoshi',\n",
              " '/Oral-History:Harry_F._Olson',\n",
              " '/Oral-History:Henry_Oman',\n",
              " '/Oral-History:Russell_D._O%27Neal',\n",
              " '/Oral-History:Eugene_O%27Neill',\n",
              " '/Oral-History:Levent_Onural',\n",
              " '/Oral-History:Alan_Oppenheim',\n",
              " '/Oral-History:Vincente_Ortega',\n",
              " '/Oral-History:Basil_Osborne',\n",
              " '/Oral-History:Jorgen_Palshoj',\n",
              " '/Oral-History:George_Pappas',\n",
              " '/Oral-History:Alice_C._Parker',\n",
              " '/Oral-History:Lynne_Parker',\n",
              " '/Oral-History:Brad_Parkinson',\n",
              " '/Oral-History:Tom_Parks',\n",
              " '/Oral-History:Sue_Parsons',\n",
              " '/Oral-History:Elisabeth_Pat%C3%A9-Cornell',\n",
              " '/Oral-History:Kumar_Patel',\n",
              " '/Oral-History:Harold_W._Paxton',\n",
              " '/Oral-History:Fay_Cobb_Payton',\n",
              " '/Oral-History:Maryly_Van_Leer_Peck',\n",
              " '/Oral-History:Irene_Peden',\n",
              " '/Oral-History:Aage_Pedersen',\n",
              " '/Oral-History:Gunnar_Pedersen',\n",
              " '/Oral-History:Arthur_D._Pelton',\n",
              " '/Oral-History:Arno_Penzias',\n",
              " '/Oral-History:Nicholas_Peppas',\n",
              " '/Oral-History:Vincent_Perry',\n",
              " '/Oral-History:Richard_Petritz',\n",
              " '/Oral-History:Rolf_Pfeifer',\n",
              " '/Oral-History:Carolyn_Phillips',\n",
              " '/Oral-History:Raymond_Pickholtz',\n",
              " '/Oral-History:John_Pierce',\n",
              " '/Oral-History:John_Pierce_(Part_2)',\n",
              " '/Oral-History:John_Pierce_(Part_3)',\n",
              " '/Oral-History:Kenneth_Plante',\n",
              " '/Oral-History:Elizabeth_Plunkett',\n",
              " '/Oral-History:Ernest_Pollard',\n",
              " '/Oral-History:Michel_Poloujadoff',\n",
              " '/Oral-History:Steve_Poston',\n",
              " '/Oral-History:Robert_Pound',\n",
              " '/Oral-History:L%C3%A9andre_George_Pourcelot',\n",
              " '/Oral-History:Joseph_J._Poveromo',\n",
              " '/Oral-History:Margaret_Pritchard',\n",
              " '/Oral-History:John_Proakis',\n",
              " '/Oral-History:Walter_Proebster',\n",
              " '/Oral-History:Emerson_W._Pugh',\n",
              " '/Oral-History:Edward_Purcell',\n",
              " '/Oral-History:Lawrence_Rabiner',\n",
              " '/Oral-History:Charles_Rader',\n",
              " '/Oral-History:Jan_Rajchman',\n",
              " '/Oral-History:William_Rambo',\n",
              " '/Oral-History:Simon_Ramo',\n",
              " '/Oral-History:Edwin_Douglas_Ramsay_Shearman',\n",
              " '/Oral-History:Norman_F._Ramsey_(1991)',\n",
              " '/Oral-History:Norman_Ramsey_(1995)',\n",
              " '/Oral-History:Madhu_G._Ranade',\n",
              " '/Oral-History:C.R._Rao',\n",
              " '/Oral-History:Bertram_Raphael',\n",
              " '/Oral-History:Buddy_Ratner',\n",
              " '/Oral-History:Wally_Read',\n",
              " '/Oral-History:Eberhardt_Rechtin',\n",
              " '/Oral-History:Robert_Rediker',\n",
              " '/Oral-History:Bill_Rehm',\n",
              " '/Oral-History:John_M._Reid',\n",
              " '/Oral-History:Gloria_Brooks_Reinish',\n",
              " '/Oral-History:Sorel_Reisman',\n",
              " '/Oral-History:Rolf_Remshardt',\n",
              " '/Oral-History:Carl_Rench',\n",
              " '/Oral-History:Robert_Riener',\n",
              " '/Oral-History:Heidi_Ries',\n",
              " '/Oral-History:Randal_Robertson',\n",
              " '/Oral-History:Denis_M._Robinson',\n",
              " '/Oral-History:Enders_Robinson',\n",
              " '/Oral-History:Leon_Robinson',\n",
              " '/Oral-History:Nathaniel_Rochester',\n",
              " '/Oral-History:Ulrich_Rohde',\n",
              " '/Oral-History:Ragnar_Rollefson',\n",
              " '/Oral-History:Richard_Rollman',\n",
              " '/Oral-History:Harold_Rosen',\n",
              " '/Oral-History:Paul_Rosen',\n",
              " '/Oral-History:Azriel_Rosenfeld',\n",
              " '/Oral-History:Ian_Ross',\n",
              " '/Oral-History:Bernie_Roth',\n",
              " '/Oral-History:George_T._Royden',\n",
              " '/Oral-History:Carl_Ruoff',\n",
              " '/Oral-History:Reginald_Russell',\n",
              " '/Oral-History:John_Douglass_Ryder',\n",
              " '/Oral-History:Chandos_Rypinski',\n",
              " '/Oral-History:Theodore_Saad',\n",
              " '/Oral-History:Shoichi_Saba',\n",
              " '/Oral-History:John_Saby',\n",
              " '/Oral-History:Murray_Sachs',\n",
              " '/Oral-History:Ken_Salisbury',\n",
              " '/Oral-History:Peter_Sandretto',\n",
              " '/Oral-History:Tadashi_Sasaki',\n",
              " '/Oral-History:Robert_Saunders',\n",
              " '/Oral-History:Stefan_Schaal',\n",
              " '/Oral-History:Ron_Schafer',\n",
              " '/Oral-History:Victor_Scheinman',\n",
              " '/Oral-History:Harold_Scherer',\n",
              " '/Oral-History:Donald_Schilling',\n",
              " '/Oral-History:Kurt_Schips',\n",
              " '/Oral-History:Johan_Schleimann-Jensen',\n",
              " '/Oral-History:Fran_Scholl_and_Aubree_Osborn',\n",
              " '/Oral-History:James_F._Scott',\n",
              " '/Oral-History:William_F._Schreiber',\n",
              " '/Oral-History:Manfred_Schroeder',\n",
              " '/Oral-History:Hans_Wilhelm_Schuessler',\n",
              " '/Oral-History:Herman_Schwan_(1992)',\n",
              " '/Oral-History:Herman_Schwan_(1999)',\n",
              " '/Oral-History:Mischa_Schwartz',\n",
              " '/Oral-History:Richard_Schwartz',\n",
              " '/Oral-History:Alex_Scott',\n",
              " '/Oral-History:Catherine_Scott',\n",
              " '/Oral-History:H._True_Seaborn',\n",
              " '/Oral-History:Ray_Sears',\n",
              " '/Oral-History:Samuel_Seely',\n",
              " '/Oral-History:Franz_Seifert',\n",
              " '/Oral-History:Lee_Semiatin',\n",
              " '/Oral-History:Jung_Uk_Seo',\n",
              " '/Oral-History:Hans_Severin',\n",
              " '/Oral-History:Trey_Shaffer',\n",
              " '/Oral-History:Betty_Shanahan',\n",
              " '/Oral-History:Carol_Shanesy',\n",
              " '/Oral-History:Claude_E._Shannon',\n",
              " '/Oral-History:Gustave_Shapiro',\n",
              " '/Oral-History:Chalmers_Sherwin',\n",
              " '/Oral-History:Masatoshi_Shima',\n",
              " '/Oral-History:Bruce_Shimano',\n",
              " '/Oral-History:Ken%27ichi_Shinoda',\n",
              " '/Oral-History:Karen_Shipp',\n",
              " '/Oral-History:Yoshiaki_Shirai',\n",
              " '/Oral-History:Dame_Stephanie_(Steve)_Shirley',\n",
              " '/Oral-History:Robert_S._Shoemaker',\n",
              " '/Oral-History:Ralph_M._Showers',\n",
              " '/Oral-History:Bruce_Shriver',\n",
              " '/Oral-History:Elsie_Shutt',\n",
              " '/Oral-History:Bruno_Siciliano',\n",
              " '/Oral-History:Roland_Siegwart',\n",
              " '/Oral-History:Daniel_Siewiorek',\n",
              " '/Oral-History:Arnold_Silver',\n",
              " '/Oral-History:Douglas_B._Silver',\n",
              " '/Oral-History:Reid_Simmons',\n",
              " '/Oral-History:Barbara_Simons',\n",
              " '/Oral-History:Michael_Sims',\n",
              " '/Oral-History:Jack_Sipress',\n",
              " '/Oral-History:William_Skillman',\n",
              " '/Oral-History:Merrill_Skolnik',\n",
              " '/Oral-History:Kenneth_F._Slater',\n",
              " '/Oral-History:Lucy_Slater',\n",
              " '/Oral-History:Martha_Sloan',\n",
              " '/Oral-History:William_Smanko',\n",
              " '/Oral-History:Chester_Smith',\n",
              " '/Oral-History:George_E._Smith',\n",
              " '/Oral-History:George_F._Smith',\n",
              " '/Oral-History:Philip_H._Smith',\n",
              " '/Oral-History:Raymond_L._Smith',\n",
              " '/Oral-History:Richard_Snelling',\n",
              " '/Oral-History:Allan_Whitenack_Snyder',\n",
              " '/Oral-History:Joel_Snyder',\n",
              " '/Oral-History:Alva_Matthews_Solomon',\n",
              " '/Oral-History:Jack_Spangler',\n",
              " '/Oral-History:James_Spilker',\n",
              " '/Oral-History:Cary_Spitzer',\n",
              " '/Oral-History:Jon_Squire',\n",
              " '/Oral-History:John_Staehlin',\n",
              " '/Oral-History:Earl_Steele',\n",
              " '/Oral-History:Luc_Steels',\n",
              " '/Oral-History:Karl_Ulrich_Stein',\n",
              " '/Oral-History:Arthur_Stern_(1993)',\n",
              " '/Oral-History:Arthur_P._Stern_(2009)',\n",
              " '/Oral-History:H._Guyford_Stever',\n",
              " '/Oral-History:Pat_Stewart',\n",
              " '/Oral-History:Irving_Stokes',\n",
              " '/Oral-History:Ellery_W._Stone',\n",
              " '/Oral-History:William_Stotz',\n",
              " '/Oral-History:Simon_David_Strauss',\n",
              " '/Oral-History:George_Wilhelm_Stroke',\n",
              " '/Oral-History:Ralph_Strong',\n",
              " '/Oral-History:Virginia_Powell_Strong',\n",
              " '/Oral-History:Gene_Strull',\n",
              " '/Oral-History:Kenneth_Sturley',\n",
              " '/Oral-History:Shigeki_Sugano',\n",
              " '/Oral-History:Takuo_Sugano',\n",
              " '/Oral-History:Takashi_Sugiyama',\n",
              " '/Oral-History:Guy_Suits',\n",
              " '/Oral-History:Gaurav_Sukhatme',\n",
              " '/Oral-History:Leo_Sullivan',\n",
              " '/Oral-History:Jerome_Suran',\n",
              " '/Oral-History:Len_Svensson',\n",
              " '/Oral-History:Margaret_Taber',\n",
              " '/Oral-History:Keiji_Tachikawa',\n",
              " '/Oral-History:Morris_Tanenbaum',\n",
              " '/Oral-History:Gerald_F._Tape',\n",
              " '/Oral-History:Patrick_R._Taylor',\n",
              " '/Oral-History:Gordon_K._Teal',\n",
              " '/Oral-History:Benjamin_R._Teare_Jr.',\n",
              " '/Oral-History:Richard_%22Dick%22_Teets',\n",
              " '/Oral-History:Helen_Thomas',\n",
              " '/Oral-History:Leonard_Thomas_Sr.',\n",
              " '/Oral-History:Richard_J._Thome',\n",
              " '/Oral-History:Bertil_Thoren',\n",
              " '/Oral-History:Chuck_Thorpe',\n",
              " '/Oral-History:Jill_Tietjen,_Kristy_Schloss,_and_Sandra_Scanlon',\n",
              " '/Oral-History:Jill_Tietjen',\n",
              " '/Oral-History:Dawn_Tilbury',\n",
              " '/Oral-History:Matthew_Tirrell',\n",
              " '/Oral-History:Daniel_Toland',\n",
              " '/Oral-History:Erwin_Tomash',\n",
              " '/Oral-History:Carme_Torras',\n",
              " '/Oral-History:Michelle_Tortolani',\n",
              " '/Oral-History:Charles_A._Totten',\n",
              " '/Oral-History:Charles_H._Townes_(1992)',\n",
              " '/Oral-History:Charles_Townes_(1991)',\n",
              " '/Oral-History:Arno_Treptow',\n",
              " '/Oral-History:Edward_Tudor',\n",
              " '/Oral-History:Masaru_Uchiyama',\n",
              " '/Oral-History:Michiyuki_Uenohara',\n",
              " '/Oral-History:Gottfried_Ungerboeck',\n",
              " '/Oral-History:Leslie_Vadasz',\n",
              " '/Oral-History:Max_Valentinuzzi',\n",
              " '/Oral-History:George_E._Valley',\n",
              " '/Oral-History:Hendrik_Van_Brussel',\n",
              " '/Oral-History:Mary_Van_Domelen',\n",
              " '/Oral-History:Theodore_Van_Duzer_(1991)',\n",
              " '/Oral-History:Theodore_Van_Duzer_(2014)',\n",
              " '/Oral-History:Thomas_Vanderslice',\n",
              " '/Oral-History:Jacques_Vanier',\n",
              " '/Oral-History:Guido_Vannucchi',\n",
              " '/Oral-History:Ralph_Veatch',\n",
              " '/Oral-History:Gianmarco_Veruggio',\n",
              " '/Oral-History:Ben_Vester',\n",
              " '/Oral-History:John_Vig',\n",
              " '/Oral-History:Oswald_Garrison_Villard',\n",
              " '/Oral-History:Andrew_Viterbi',\n",
              " '/Oral-History:Fred_Vogel',\n",
              " '/Oral-History:Joseph_Vogelman',\n",
              " '/Oral-History:Guilfred_%22Guil%22_Vogt',\n",
              " '/Oral-History:Richard_Volpe',\n",
              " '/Oral-History:Glen_Wade',\n",
              " '/Oral-History:Charles_Wagner',\n",
              " '/Oral-History:Benjamin_Wah',\n",
              " '/Oral-History:Ken_Waldron',\n",
              " '/Oral-History:Hal_Walker',\n",
              " '/Oral-History:J._T._Wallmark',\n",
              " '/Oral-History:Prinda_Wanakule',\n",
              " '/Oral-History:Chris_Warner',\n",
              " '/Oral-History:Josephine_Webb',\n",
              " '/Oral-History:Ernst_Weber_(1988)',\n",
              " '/Oral-History:Ernst_Weber_(1991)',\n",
              " '/Oral-History:Roger_Webster',\n",
              " '/Oral-History:Paul_K._Weimer',\n",
              " '/Oral-History:Bruno_Weinschel',\n",
              " '/Oral-History:Herbert_Weiss',\n",
              " '/Oral-History:Max_Weiss',\n",
              " '/Oral-History:Walter_Welkowitz',\n",
              " '/Oral-History:Harold_A._Wheeler_(1985)',\n",
              " '/Oral-History:Harold_Wheeler_(1991)',\n",
              " '/Oral-History:John_Whinnery',\n",
              " '/Oral-History:Edwin_Lee_White',\n",
              " '/Oral-History:Marvin_White',\n",
              " '/Oral-History:Richard_M._White',\n",
              " '/Oral-History:Stanley_A._White',\n",
              " '/Oral-History:Eugene_Whitney',\n",
              " '/Oral-History:Telle_Whitney',\n",
              " '/Oral-History:Red_Whittaker',\n",
              " '/Oral-History:Bernard_Widrow',\n",
              " '/Oral-History:Jim_Wiener',\n",
              " '/Oral-History:Jerome_Wiesner',\n",
              " '/Oral-History:Silvia_Wilbur',\n",
              " '/Oral-History:Brian_Wilcox',\n",
              " '/Oral-History:George_Wilcox',\n",
              " '/Oral-History:Emily_Willbanks',\n",
              " '/Oral-History:G._Paul_Willhite',\n",
              " '/Oral-History:Jan_Williams',\n",
              " '/Oral-History:Kimball_Williams',\n",
              " '/Oral-History:Michael_Williams',\n",
              " '/Oral-History:Alexander_M._Wilson',\n",
              " '/Oral-History:Alan_Winfield',\n",
              " '/Oral-History:Arthur_Winston',\n",
              " '/Oral-History:Penny_Wirsing',\n",
              " '/Oral-History:Irving_Wolff',\n",
              " '/Oral-History:Murray_Wonham',\n",
              " '/Oral-History:Roy_Woodall',\n",
              " '/Oral-History:Victor_Wouk',\n",
              " '/Oral-History:Diane_Wray',\n",
              " '/Oral-History:Jing_Xiao',\n",
              " '/Oral-History:Sakae_Yamamura',\n",
              " '/Oral-History:Takashi_Yamanaka',\n",
              " '/Oral-History:Mark_Yim',\n",
              " '/Oral-History:Susumo_Yoshida',\n",
              " '/Oral-History:David_M._Young_Jr.',\n",
              " '/Oral-History:Lotfi_Zadeh',\n",
              " '/Oral-History:Baldomir_Zajc',\n",
              " '/Oral-History:Lars_Zetterberg',\n",
              " '/Oral-History:Anthony_Zimbalatti',\n",
              " '/Oral-History:Jacob_Ziv',\n",
              " '/Oral-History:Ji%C5%99%C3%AD_Zlatu%C5%A1ka',\n",
              " '/Oral-History:Konrad_Zuse',\n",
              " '/Oral-History:Vladimir_Zworykin']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Individual Oral Histories"
      ],
      "metadata": {
        "id": "-4ylJlz1wfH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interviews = pd.DataFrame(columns = ['person', 'interview', 'bio', 'section', 'speaker', 'text'])\n",
        "\n",
        "for link in links[48:50]:\n",
        "    driver.get(\"https://ethw.org\" + link)\n",
        "    content = driver.page_source\n",
        "    soup = BeautifulSoup(content)\n",
        "    row = [[link.split(':')[1],\n",
        "        soup.find('span', {'id': 'About_the_Interview'}).find_next('p').get_text() if soup.find('span', {'id': 'About_the_Interview'}) is not None else '', \n",
        "        soup.find_all('h2')[0].find_next('p').get_text() if soup.find_all('h2') is not None else '', \n",
        "        p.find_previous('h3').find_next('span', {'class' : 'mw-headline'}).get_text() if p.find_previous('h3') is not None else '',\n",
        "        p.find('b').get_text(), \n",
        "        p.findNext('p').get_text()\n",
        "    ] for p in soup.find_all('p') if (p.find('b') is not None) and (p.findNext('p') is not None)]\n",
        "    interviews = pd.concat([interviews, pd.DataFrame(row, columns = ['person', 'interview', 'bio', 'section', 'speaker', 'text'])], axis = 0)\n",
        "\n",
        "interviews = interviews.replace(r'\\n',' ', regex=True)\n",
        "\n",
        "interviews['speaker'] = interviews['speaker'].replace(r':', '', regex=True)"
      ],
      "metadata": {
        "id": "5DaLdzJbvX72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ROWieDRUv3_o",
        "outputId": "c7f9a3e4-dd83-46ba-9dd9-c5514b80f4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               person                                          interview  \\\n",
              "0    Henry_B._Abajian  HENRY B. ABAJIAN: An Interview Conducted by Fr...   \n",
              "1    Henry_B._Abajian  HENRY B. ABAJIAN: An Interview Conducted by Fr...   \n",
              "2    Henry_B._Abajian  HENRY B. ABAJIAN: An Interview Conducted by Fr...   \n",
              "3    Henry_B._Abajian  HENRY B. ABAJIAN: An Interview Conducted by Fr...   \n",
              "4    Henry_B._Abajian  HENRY B. ABAJIAN: An Interview Conducted by Fr...   \n",
              "..                ...                                                ...   \n",
              "141     Willis_Adcock  WILLIS ADCOCK: An Interview Conducted by David...   \n",
              "142     Willis_Adcock  WILLIS ADCOCK: An Interview Conducted by David...   \n",
              "143     Willis_Adcock  WILLIS ADCOCK: An Interview Conducted by David...   \n",
              "144     Willis_Adcock  WILLIS ADCOCK: An Interview Conducted by David...   \n",
              "145     Willis_Adcock  WILLIS ADCOCK: An Interview Conducted by David...   \n",
              "\n",
              "                                                   bio  \\\n",
              "0    Abajian got an Electrical Engineering degree i...   \n",
              "1    Abajian got an Electrical Engineering degree i...   \n",
              "2    Abajian got an Electrical Engineering degree i...   \n",
              "3    Abajian got an Electrical Engineering degree i...   \n",
              "4    Abajian got an Electrical Engineering degree i...   \n",
              "..                                                 ...   \n",
              "141  Adcock was born in Canada but moved to the US ...   \n",
              "142  Adcock was born in Canada but moved to the US ...   \n",
              "143  Adcock was born in Canada but moved to the US ...   \n",
              "144  Adcock was born in Canada but moved to the US ...   \n",
              "145  Adcock was born in Canada but moved to the US ...   \n",
              "\n",
              "                    section  speaker  \\\n",
              "0    Educational Background  Nebeker   \n",
              "1    Educational Background  Abajian   \n",
              "2    Educational Background  Nebeker   \n",
              "3             Radiation Lab  Abajian   \n",
              "4             Radiation Lab  Nebeker   \n",
              "..                      ...      ...   \n",
              "141   Family and retirement   Morton   \n",
              "142   Family and retirement   Adcock   \n",
              "143   Family and retirement   Morton   \n",
              "144   Family and retirement   Adcock   \n",
              "145   Family and retirement   Morton   \n",
              "\n",
              "                                                  text  \n",
              "0    This is an interview with Henry Abajian on the...  \n",
              "1    In 1938 I graduated with an electrical enginee...  \n",
              "2    What were you particularly interested in at th...  \n",
              "3    It was all power engineering, and the electron...  \n",
              "4                      That first year of operation.    \n",
              "..                                                 ...  \n",
              "141                                            Okay.    \n",
              "142                    What’s your area of interest?    \n",
              "143  I’m an historian. I work for the IEEE, but I w...  \n",
              "144                                           Where?    \n",
              "145  At Georgia Tech in Atlanta. I was hired here t...  \n",
              "\n",
              "[293 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6a10ba6-5421-4b77-83d8-0a7a1a445617\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person</th>\n",
              "      <th>interview</th>\n",
              "      <th>bio</th>\n",
              "      <th>section</th>\n",
              "      <th>speaker</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>HENRY B. ABAJIAN: An Interview Conducted by Fr...</td>\n",
              "      <td>Abajian got an Electrical Engineering degree i...</td>\n",
              "      <td>Educational Background</td>\n",
              "      <td>Nebeker</td>\n",
              "      <td>This is an interview with Henry Abajian on the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>HENRY B. ABAJIAN: An Interview Conducted by Fr...</td>\n",
              "      <td>Abajian got an Electrical Engineering degree i...</td>\n",
              "      <td>Educational Background</td>\n",
              "      <td>Abajian</td>\n",
              "      <td>In 1938 I graduated with an electrical enginee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>HENRY B. ABAJIAN: An Interview Conducted by Fr...</td>\n",
              "      <td>Abajian got an Electrical Engineering degree i...</td>\n",
              "      <td>Educational Background</td>\n",
              "      <td>Nebeker</td>\n",
              "      <td>What were you particularly interested in at th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>HENRY B. ABAJIAN: An Interview Conducted by Fr...</td>\n",
              "      <td>Abajian got an Electrical Engineering degree i...</td>\n",
              "      <td>Radiation Lab</td>\n",
              "      <td>Abajian</td>\n",
              "      <td>It was all power engineering, and the electron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Henry_B._Abajian</td>\n",
              "      <td>HENRY B. ABAJIAN: An Interview Conducted by Fr...</td>\n",
              "      <td>Abajian got an Electrical Engineering degree i...</td>\n",
              "      <td>Radiation Lab</td>\n",
              "      <td>Nebeker</td>\n",
              "      <td>That first year of operation.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>Willis_Adcock</td>\n",
              "      <td>WILLIS ADCOCK: An Interview Conducted by David...</td>\n",
              "      <td>Adcock was born in Canada but moved to the US ...</td>\n",
              "      <td>Family and retirement</td>\n",
              "      <td>Morton</td>\n",
              "      <td>Okay.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>Willis_Adcock</td>\n",
              "      <td>WILLIS ADCOCK: An Interview Conducted by David...</td>\n",
              "      <td>Adcock was born in Canada but moved to the US ...</td>\n",
              "      <td>Family and retirement</td>\n",
              "      <td>Adcock</td>\n",
              "      <td>What’s your area of interest?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>Willis_Adcock</td>\n",
              "      <td>WILLIS ADCOCK: An Interview Conducted by David...</td>\n",
              "      <td>Adcock was born in Canada but moved to the US ...</td>\n",
              "      <td>Family and retirement</td>\n",
              "      <td>Morton</td>\n",
              "      <td>I’m an historian. I work for the IEEE, but I w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>Willis_Adcock</td>\n",
              "      <td>WILLIS ADCOCK: An Interview Conducted by David...</td>\n",
              "      <td>Adcock was born in Canada but moved to the US ...</td>\n",
              "      <td>Family and retirement</td>\n",
              "      <td>Adcock</td>\n",
              "      <td>Where?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>Willis_Adcock</td>\n",
              "      <td>WILLIS ADCOCK: An Interview Conducted by David...</td>\n",
              "      <td>Adcock was born in Canada but moved to the US ...</td>\n",
              "      <td>Family and retirement</td>\n",
              "      <td>Morton</td>\n",
              "      <td>At Georgia Tech in Atlanta. I was hired here t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>293 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6a10ba6-5421-4b77-83d8-0a7a1a445617')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6a10ba6-5421-4b77-83d8-0a7a1a445617 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6a10ba6-5421-4b77-83d8-0a7a1a445617');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#interviews.to_excel(\"scraped_interviews.xlsx\")\n",
        "#files.download(\"scraped_interviews.xlsx\")"
      ],
      "metadata": {
        "id": "Q_24P9wDdoSV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c4a90edb9d5438aa9e9387e4d704091": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5003410dd60d43faa2dee15328d4f54f",
              "IPY_MODEL_84d6305d0f2a46dba9d9d6fb84d6f70f",
              "IPY_MODEL_bed4c4d6cc92449cb795297e0fb94149"
            ],
            "layout": "IPY_MODEL_74a791de36644b85bee19cc36caa5805"
          }
        },
        "5003410dd60d43faa2dee15328d4f54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21cccf4480e43d0b30c1a6dda736fb0",
            "placeholder": "​",
            "style": "IPY_MODEL_417336142a6f434093cbdd6fcee7c747",
            "value": "Downloading: 100%"
          }
        },
        "84d6305d0f2a46dba9d9d6fb84d6f70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d23f637143b54292b683709efd550b70",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c854e1f291640c3b2422d8e83ede99b",
            "value": 231508
          }
        },
        "bed4c4d6cc92449cb795297e0fb94149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2301cc6bbad4d58b901983bf93c7d83",
            "placeholder": "​",
            "style": "IPY_MODEL_1fd2568180504acba9519205e50ddca7",
            "value": " 226k/226k [00:00&lt;00:00, 4.31MB/s]"
          }
        },
        "74a791de36644b85bee19cc36caa5805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21cccf4480e43d0b30c1a6dda736fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "417336142a6f434093cbdd6fcee7c747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d23f637143b54292b683709efd550b70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c854e1f291640c3b2422d8e83ede99b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2301cc6bbad4d58b901983bf93c7d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fd2568180504acba9519205e50ddca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3909dc2e5dba4424a805b575259b335a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10f1916f08164f74a57eabbbee3ad294",
              "IPY_MODEL_964d0c8ca73a40dda54a6f3d1a93eff1",
              "IPY_MODEL_148a5bd765134a5da72cda1fd04669a2"
            ],
            "layout": "IPY_MODEL_3edccff71d6e4da79d391e2a534e3522"
          }
        },
        "10f1916f08164f74a57eabbbee3ad294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0779ef32f0d74fb08cf23b647b5b6045",
            "placeholder": "​",
            "style": "IPY_MODEL_b2bcf7bfc9804a8bbe46a73d5e8c6952",
            "value": "Downloading: 100%"
          }
        },
        "964d0c8ca73a40dda54a6f3d1a93eff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_844c1c0227664906be286e1bb147ad82",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b05f772268a4018933ddf6fa65f919c",
            "value": 28
          }
        },
        "148a5bd765134a5da72cda1fd04669a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94278ea9681f43bbae1f4b309c0a59ff",
            "placeholder": "​",
            "style": "IPY_MODEL_92c1ad0638ed499f8995b03e30580c77",
            "value": " 28.0/28.0 [00:00&lt;00:00, 737B/s]"
          }
        },
        "3edccff71d6e4da79d391e2a534e3522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0779ef32f0d74fb08cf23b647b5b6045": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2bcf7bfc9804a8bbe46a73d5e8c6952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "844c1c0227664906be286e1bb147ad82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b05f772268a4018933ddf6fa65f919c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94278ea9681f43bbae1f4b309c0a59ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c1ad0638ed499f8995b03e30580c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b79b1ca5034b6cbc3eea6d9b577956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92d92426dd1b4c28b5e691812c79292e",
              "IPY_MODEL_b7e5ae1286da4a3f92cca75adb89934d",
              "IPY_MODEL_b60a171b67fa4d13a2cac39eeca7958b"
            ],
            "layout": "IPY_MODEL_55f86f21b200411b97d6c6c769677222"
          }
        },
        "92d92426dd1b4c28b5e691812c79292e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1293a89f604c9192c4dcddf799455b",
            "placeholder": "​",
            "style": "IPY_MODEL_a985a5bcf5924357a9cd54d2f436985a",
            "value": "Downloading: 100%"
          }
        },
        "b7e5ae1286da4a3f92cca75adb89934d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f923ae8c7704c5d80de08020efbb2a3",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d97b41387de649ba82175311307f3977",
            "value": 483
          }
        },
        "b60a171b67fa4d13a2cac39eeca7958b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08328134a8ae4b6fa405cccaeb5e7e87",
            "placeholder": "​",
            "style": "IPY_MODEL_aed4a7824bde404fb85b5fd9dcf704c6",
            "value": " 483/483 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "55f86f21b200411b97d6c6c769677222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1293a89f604c9192c4dcddf799455b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a985a5bcf5924357a9cd54d2f436985a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f923ae8c7704c5d80de08020efbb2a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97b41387de649ba82175311307f3977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08328134a8ae4b6fa405cccaeb5e7e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed4a7824bde404fb85b5fd9dcf704c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a746becb328c4fa78160a0903440800a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7cbfe96bf114b4d8057e3ce2920b510",
              "IPY_MODEL_2c3989f20e1149939aa23d5f505c56b5",
              "IPY_MODEL_99b82a33592247009d0f5201ba246310"
            ],
            "layout": "IPY_MODEL_9f6dfcd2d6c14667bfabf802efcebedd"
          }
        },
        "e7cbfe96bf114b4d8057e3ce2920b510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b854b213bbdf4ef798ffb24a36576892",
            "placeholder": "​",
            "style": "IPY_MODEL_2f0ec48f2b204bbbbdda579352691f98",
            "value": "Downloading: 100%"
          }
        },
        "2c3989f20e1149939aa23d5f505c56b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffea5c307fa3459aa603e743a4553d83",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_400bdce66bcb4beb945950ce0603a606",
            "value": 267967963
          }
        },
        "99b82a33592247009d0f5201ba246310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa6c1673a674eaba2f915fdc4547b11",
            "placeholder": "​",
            "style": "IPY_MODEL_ed5e737d76c842298fca71f69271ec12",
            "value": " 256M/256M [00:05&lt;00:00, 51.0MB/s]"
          }
        },
        "9f6dfcd2d6c14667bfabf802efcebedd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b854b213bbdf4ef798ffb24a36576892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0ec48f2b204bbbbdda579352691f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffea5c307fa3459aa603e743a4553d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400bdce66bcb4beb945950ce0603a606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baa6c1673a674eaba2f915fdc4547b11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed5e737d76c842298fca71f69271ec12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}